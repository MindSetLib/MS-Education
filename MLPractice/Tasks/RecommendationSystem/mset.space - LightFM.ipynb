{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ddad4e",
   "metadata": {},
   "source": [
    "# __Использованные материалы__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acffaa9",
   "metadata": {},
   "source": [
    "* [LightFM Github](https://github.com/lyst/lightfm)\n",
    "* [LightFM documentation](https://making.lyst.com/lightfm/docs/quickstart.html)\n",
    "* [Google recommendation systems course](https://developers.google.com/machine-learning/recommendation)\n",
    "* [Recommender system using Bayesian personalized ranking](https://towardsdatascience.com/recommender-system-using-bayesian-personalized-ranking-d30e98bba0b9)\n",
    "* [Learning to Rank Sketchfab Models with LightFM](https://www.ethanrosenthal.com/2016/11/07/implicit-mf-part-2/)\n",
    "* [How to build a Movie Recommender System in Python using LightFm](https://towardsdatascience.com/how-to-build-a-movie-recommender-system-in-python-using-lightfm-8fa49d7cbe3b)\n",
    "* [The Movies Dataset](https://www.kaggle.com/rounakbanik/the-movies-dataset/home?select=ratings_small.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bcf4f4",
   "metadata": {},
   "source": [
    "# __Краткое введение__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2818c48b",
   "metadata": {},
   "source": [
    "__LightFM__ - это реализация на Python'е ряда популярных алгоритмов рекомендаций, включая эффективную реализацию BPR и WARP. Он прост в использовании, быстр (благодаря многопоточности) и дает высококачественные результаты. <br>\n",
    "Существуют две основные стратегии создания рекомендательных систем: \n",
    "* __Content-based Filtering__\n",
    "* __Collaborative filtering__\n",
    "\n",
    "На практике чаще всего они используются в совокупности.<br>\n",
    "<em>Далее для удобства будет использоваться термин item, который подразумевает под собой сущности, рекомендуемые системой.</em>\n",
    "\n",
    "### __Content-based Filtering__ \n",
    "Данный подход предполагает работу с метаданными пользователя, которые собираются различными способами:\n",
    "* __explicit__ - пользователь заполняет анкеты для выявление предпочтений, к примеру оценивает какой-то item по дифференцированной шкале.<br>\n",
    "* __implicit__ - все действия пользователя протоколируются для выявления предпочтений, к примеру переход по ссылками, информация о компьютере пользователя и тп.<br>\n",
    "\n",
    "### __Collaborative filtering__ \n",
    "Данный подход использует группировку пользователей и item'ов по каким-то сходствам/критериям. Будет реализоваться следующая логика \"Пользователям, которым понравился item $X$, также нравились item'ы $Y$\". Похожесть как правило определяется следующими методами:<br>\n",
    "* __Content-based__ - на основании характеристик item'ов и пользователей.<br>\n",
    "* __Transaction-based__ - на основании того, входили ли item'ы в одну транзакцию, а пользователи совершали схожие действия.<br>\n",
    "\n",
    "### Machine-learned ranking \n",
    "В __LightFM__ представлены два классических подхода MLR'а:\n",
    "* __Bayesian Personalized Ranking (BLR)__ \n",
    "* __Weighted Approximate-Rank Pairwise (WARP)__ \n",
    "\n",
    "### Bayesian Personalized Ranking \n",
    "Основная идея заключается в выборке и попарном сравнение положительных и отрицательных item'ов. Алгоритм в упрощенном виде можно представить следующим образом:\n",
    "1. Случайным образом возьмем пользователя $u$ и item $i$, который ранее был выбран пользователем, в таком случае item $i$ будет считаться <em>положительным.</em>\n",
    "2. Случайным образом возьмем item $j$, который был выбран пользователем <em>реже</em>, чем $i$ (в том числе, который пользователь никогда не выбирал), в таком случае item $j$ будет считаться <em>отрицательным.</em>\n",
    "3. Вычисляем оценку $p_{ui}$ и $p_{uj}$ пользователя $u$, а также положительного item'а $i$ и отрицательного item'а $j$ соответственно.\n",
    "4. Находим разницу между положительными и отрицательными оценками, как $x_{uij} = p_{ui} - p_{uj}.$ \n",
    "5. Пропускаем эту разницу через сигмоид и используем ее для вычисления веса для обновления всех параметров модели с помощью градиентного шага(SGD).\n",
    "\n",
    "### Weighted Approximate-Rank Pairwise\n",
    "Концепция данного подхода схожа с BPR, за исключением случаев, когда происходит градиентный шаг:\n",
    "* В BPR градиентный шаг происходит каждый раз с разницей в качестве веса.\n",
    "* WARP совершает градиентный шаг только в случае неверного предсказания (т.е. оценка отрицательного item'а больше положительного). Если предсказание было верным, то продолжаем выбирать отрицательные item'ы, пока не получим неверный прогноз или не достигнем некоторого порогового значения.\n",
    "\n",
    "Для этих целей WARP предоставляет два гиперпараметра:\n",
    "1. __Margin__ - определяет насколько ошибочным должен быть прогноз для совершения градиентного шага. \n",
    "2. __Cutoff__ - определяет сколько раз мы готовы выбирать отрицательные примеры, пытаясь получить неверное предсказание, прежде чем откажемся и перейдем к следующему пользователю.\n",
    "\n",
    "<em>Автор статьи [Learning to Rank Sketchfab Models with LightFM](https://www.ethanrosenthal.com/2016/11/07/implicit-mf-part-2/) утверждает, что на практике вероятнее всего WARP предпочтительнее для большинства рекомендательных систем, нежели BPR.</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6920de3c",
   "metadata": {},
   "source": [
    "# __Тестовый пример__\n",
    "Попробуем реализовать простейшую рекомендательную систему на основе [датасета, предоставляемого LightFM'ом.](https://grouplens.org/datasets/movielens/100k/)\n",
    "## __Установка зависимостей__\n",
    "### __Виртуальное окружение__\n",
    "Для его создания будет использоваться conda.\n",
    "#### Установка conda для Windows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fbbe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cmd\n",
    "@\"%SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\" -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command \"[System.Net.ServicePointManager]::SecurityProtocol = 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))\" && SET \"PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin\"\n",
    "ECHO Y | choco install miniconda3 --params=\"'/AddToPath:1'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9f6de5",
   "metadata": {},
   "source": [
    "#### Установка conda для Ubuntu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d7434",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "sudo apt update --yes\n",
    "sudo apt upgrade --yes\n",
    "\n",
    "wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh\n",
    "bash ~/miniconda.sh -b -p ~/miniconda \n",
    "rm ~/miniconda.sh\n",
    "\n",
    "export PATH=~/miniconda/bin:$PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51258c5",
   "metadata": {},
   "source": [
    "#### Создаем и активируем виртуальное окружение c помощью команд <br>\n",
    "```\n",
    "conda create -n LightFM-env\n",
    "conda activate LightFM-env\n",
    "pip install --user ipykernel\n",
    "python -m ipykernel install --user --name=LightFM-env\n",
    "```\n",
    "#### Затем добавляем новый кернел в нотбук\n",
    "<em>По неведомым мне причинам подход к созданию виртуальной среды через conda в Windows упорно не хотел работать и активация виртуального окружения происходила только через cmd (Powershell отказывался работать). Полдня стараний зафиксить эту проблему не увенчались успехом, соответственно терминал был не доступен, поэтому дальше будет описан подход через venv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62524e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from platform import python_version\n",
    "if float(python_version()[:-2]) < 3.3: #Поскольку venv является стандартной библиотекой в Python начиная с версии 3.3.*\n",
    "    print(\"Upgrade Python to use venv library features for correct further work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bfe1214-d0aa-45b2-915a-7acddda78033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\python37\\lib\\site-packages (21.2.4)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m venv LightFM-env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8229ee66",
   "metadata": {},
   "source": [
    "#### Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e22619-8094-42a0-b03d-158dfb72b9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.19042.1165]\r\n",
      "(c) Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "C:\\A.Mindset\\internship_ds\\LightFM>.\\LightFM-env\\Scripts\\activate\n",
      "\r\n",
      "(LightFM-env) C:\\A.Mindset\\internship_ds\\LightFM>python -m pip install --upgrade pip\n",
      "Collecting pip\r\n",
      "  Using cached pip-21.2.4-py3-none-any.whl (1.6 MB)\r\n",
      "Installing collected packages: pip\r\n",
      "  Attempting uninstall: pip\r\n",
      "    Found existing installation: pip 20.1.1\r\n",
      "    Uninstalling pip-20.1.1:\r\n",
      "      Successfully uninstalled pip-20.1.1\r\n",
      "Successfully installed pip-21.2.4\r\n",
      "\r\n",
      "(LightFM-env) C:\\A.Mindset\\internship_ds\\LightFM>pip install ipykernel\n",
      "Collecting ipykernel\r\n",
      "  Using cached ipykernel-6.2.0-py3-none-any.whl (122 kB)\r\n",
      "Collecting tornado<7.0,>=4.2\r\n",
      "  Using cached tornado-6.1-cp37-cp37m-win_amd64.whl (422 kB)\r\n",
      "Collecting debugpy<2.0,>=1.0.0\r\n",
      "  Using cached debugpy-1.4.1-cp37-cp37m-win_amd64.whl (4.4 MB)\r\n",
      "Collecting jupyter-client<8.0\r\n",
      "  Using cached jupyter_client-7.0.0-py3-none-any.whl (122 kB)\r\n",
      "Collecting argcomplete>=1.12.3\r\n",
      "  Using cached argcomplete-1.12.3-py2.py3-none-any.whl (38 kB)\r\n",
      "Collecting importlib-metadata<5\r\n",
      "  Using cached importlib_metadata-4.6.4-py3-none-any.whl (17 kB)\r\n",
      "Collecting matplotlib-inline<0.2.0,>=0.1.0\r\n",
      "  Using cached matplotlib_inline-0.1.2-py3-none-any.whl (8.2 kB)\r\n",
      "Collecting ipython<8.0,>=7.23.1\r\n",
      "  Using cached ipython-7.26.0-py3-none-any.whl (786 kB)\r\n",
      "Collecting traitlets<6.0,>=4.1.0\r\n",
      "  Using cached traitlets-5.0.5-py3-none-any.whl (100 kB)\r\n",
      "Collecting zipp>=0.5\r\n",
      "  Using cached zipp-3.5.0-py3-none-any.whl (5.7 kB)\r\n",
      "Collecting typing-extensions>=3.6.4\r\n",
      "  Using cached typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel) (47.1.0)\r\n",
      "Collecting decorator\r\n",
      "  Using cached decorator-5.0.9-py3-none-any.whl (8.9 kB)\r\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\r\n",
      "  Using cached prompt_toolkit-3.0.19-py3-none-any.whl (368 kB)\r\n",
      "Collecting pygments\r\n",
      "  Using cached Pygments-2.10.0-py3-none-any.whl (1.0 MB)\r\n",
      "Collecting backcall\r\n",
      "  Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)\r\n",
      "Collecting colorama\r\n",
      "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\r\n",
      "Collecting jedi>=0.16\r\n",
      "  Using cached jedi-0.18.0-py2.py3-none-any.whl (1.4 MB)\r\n",
      "Collecting pickleshare\r\n",
      "  Using cached pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\r\n",
      "Collecting parso<0.9.0,>=0.8.0\r\n",
      "  Using cached parso-0.8.2-py2.py3-none-any.whl (94 kB)\r\n",
      "Collecting nest-asyncio>=1.5\r\n",
      "  Using cached nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB)\r\n",
      "Collecting pyzmq>=13\r\n",
      "  Using cached pyzmq-22.2.1-cp37-cp37m-win_amd64.whl (1.1 MB)\r\n",
      "Collecting python-dateutil>=2.1\r\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\r\n",
      "Collecting entrypoints\r\n",
      "  Using cached entrypoints-0.3-py2.py3-none-any.whl (11 kB)\r\n",
      "Collecting jupyter-core>=4.6.0\r\n",
      "  Using cached jupyter_core-4.7.1-py3-none-any.whl (82 kB)\r\n",
      "Collecting pywin32>=1.0\r\n",
      "  Using cached pywin32-301-cp37-cp37m-win_amd64.whl (9.2 MB)\r\n",
      "Collecting wcwidth\r\n",
      "  Using cached wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\r\n",
      "Collecting six>=1.5\r\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\r\n",
      "Collecting ipython-genutils\r\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\r\n",
      "Installing collected packages: ipython-genutils, zipp, wcwidth, typing-extensions, traitlets, six, pywin32, parso, tornado, pyzmq, python-dateutil, pygments, prompt-toolkit, pickleshare, nest-asyncio, matplotlib-inline, jupyter-core, jedi, importlib-metadata, entrypoints, decorator, colorama, backcall, jupyter-client, ipython, debugpy, argcomplete, ipykernel\r\n",
      "Successfully installed argcomplete-1.12.3 backcall-0.2.0 colorama-0.4.4 debugpy-1.4.1 decorator-5.0.9 entrypoints-0.3 importlib-metadata-4.6.4 ipykernel-6.2.0 ipython-7.26.0 ipython-genutils-0.2.0 jedi-0.18.0 jupyter-client-7.0.0 jupyter-core-4.7.1 matplotlib-inline-0.1.2 nest-asyncio-1.5.1 parso-0.8.2 pickleshare-0.7.5 prompt-toolkit-3.0.19 pygments-2.10.0 python-dateutil-2.8.2 pywin32-301 pyzmq-22.2.1 six-1.16.0 tornado-6.1 traitlets-5.0.5 typing-extensions-3.10.0.0 wcwidth-0.2.5 zipp-3.5.0\r\n",
      "\r\n",
      "(LightFM-env) C:\\A.Mindset\\internship_ds\\LightFM>python -m ipykernel install --name=LightFM-env\n",
      "Installed kernelspec LightFM-env in C:\\ProgramData\\jupyter\\kernels\\lightfm-env\r\n",
      "\r\n",
      "(LightFM-env) C:\\A.Mindset\\internship_ds\\LightFM>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    ".\\LightFM-env\\Scripts\\activate\n",
    "python -m pip install --upgrade pip\n",
    "pip install ipykernel\n",
    "python -m ipykernel install --name=LightFM-env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6848455",
   "metadata": {},
   "source": [
    "#### Затем перезапускаем нотбук через виртуальную среду и добавляем новый кернел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "172b2a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available kernels:\n",
      "  python3        c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\share\\jupyter\\kernels\\python3\n",
      "  lightfm-env    C:\\ProgramData\\jupyter\\kernels\\lightfm-env\n"
     ]
    }
   ],
   "source": [
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9928d23c",
   "metadata": {},
   "source": [
    "#### Ubuntu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e2f6a-bd0a-4e96-975a-cadaff6f3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "source LightFM-env/bin/activate\n",
    "python -m pip install --upgrade pip\n",
    "pip install ipykernel\n",
    "python -m ipykernel install --name=LightFM-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780eca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69949ab5",
   "metadata": {},
   "source": [
    "#### Затем перезапускаем нотбук через виртуальную среду и добавляем новый кернел"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b8486f",
   "metadata": {},
   "source": [
    "### Установка библиотек для тестового примера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15e70821-e89a-4d7a-a8e3-4ed974090075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightfm\n",
      "  Using cached lightfm-1.16.tar.gz (310 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.21.2-cp37-cp37m-win_amd64.whl (14.0 MB)\n",
      "Collecting scipy>=0.17.0\n",
      "  Using cached scipy-1.7.1-cp37-cp37m-win_amd64.whl (33.6 MB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-0.24.2-cp37-cp37m-win_amd64.whl (6.8 MB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.2-py3-none-any.whl (59 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.4-py3-none-any.whl (36 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Using legacy 'setup.py install' for lightfm, since package 'wheel' is not installed.\n",
      "Installing collected packages: numpy, urllib3, threadpoolctl, scipy, joblib, idna, charset-normalizer, certifi, scikit-learn, requests, lightfm\n",
      "    Running setup.py install for lightfm: started\n",
      "    Running setup.py install for lightfm: finished with status 'done'\n",
      "Successfully installed certifi-2021.5.30 charset-normalizer-2.0.4 idna-3.2 joblib-1.0.1 lightfm-1.16 numpy-1.21.2 requests-2.26.0 scikit-learn-0.24.2 scipy-1.7.1 threadpoolctl-2.2.0 urllib3-1.26.6\n",
      "Requirement already satisfied: numpy in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (1.21.2)\n",
      "Requirement already satisfied: scipy in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from scipy) (1.21.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightfm\n",
    "!pip install numpy\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f7ccd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорт необходимых библиотек для тестового примера\n",
    "import numpy as np\n",
    "from lightfm.datasets import fetch_movielens #метод lightfm для извлечения данных фильма\n",
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f6dc0096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 49906 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "#Получаем данные фильма с минимальным рейтингом 4\n",
    "data = fetch_movielens(min_rating = 4.0)\n",
    "\n",
    "#Отобразим данные\n",
    "print(repr(data['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "114aa879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 3\n",
      "     Known positives:\n",
      "        Seven (Se7en) (1995)\n",
      "        Contact (1997)\n",
      "        Starship Troopers (1997)\n",
      "     Recommended:\n",
      "        Scream (1996)\n",
      "        Air Force One (1997)\n",
      "        Game, The (1997)\n",
      "User 25\n",
      "     Known positives:\n",
      "        Dead Man Walking (1995)\n",
      "        Star Wars (1977)\n",
      "        Fargo (1996)\n",
      "     Recommended:\n",
      "        English Patient, The (1996)\n",
      "        Contact (1997)\n",
      "        Titanic (1997)\n",
      "User 451\n",
      "     Known positives:\n",
      "        Twelve Monkeys (1995)\n",
      "        Babe (1995)\n",
      "        Mr. Holland's Opus (1995)\n",
      "     Recommended:\n",
      "        Raiders of the Lost Ark (1981)\n",
      "        Amadeus (1984)\n",
      "        Silence of the Lambs, The (1991)\n"
     ]
    }
   ],
   "source": [
    "#Создадим модель\n",
    "model = LightFM(loss = 'warp')\n",
    "#Тренировка\n",
    "model.fit(data['train'], epochs=30, num_threads=2)\n",
    "\n",
    "#Рекомендательная функция\n",
    "def sample_recommendation(model, data, user_ids):\n",
    "    #Число пользователей и фильмов в обучающем наборе\n",
    "    n_users, n_items = data['train'].shape\n",
    "    for user_id in user_ids:\n",
    "    \t#Фильмы, которые уже понравились пользователям\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
    "        #Предсказание фильмов, которые им понравится\n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "        #Сортирует результат по оценке\n",
    "        top_items = data['item_labels'][np.argsort(-scores)]\n",
    "        #Отображение результатов\n",
    "        print(\"User %s\" % user_id)\n",
    "        print(\"     Known positives:\")\n",
    "\n",
    "        for x in known_positives[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "\n",
    "        print(\"     Recommended:\")\n",
    "\n",
    "        for x in top_items[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "            \n",
    "sample_recommendation(model, data, [3, 25, 451])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797024bd",
   "metadata": {},
   "source": [
    "# __Работа с kaggle датасетом__\n",
    "Для этих целей возьмем датасет [The Movies Dataset](https://www.kaggle.com/rounakbanik/the-movies-dataset/home?select=keywords.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "416f7e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Using cached kaggle-1.5.12.tar.gz (58 kB)\n",
      "Requirement already satisfied: six>=1.10 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from kaggle) (2021.5.30)\n",
      "Requirement already satisfied: python-dateutil in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from kaggle) (2.26.0)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.62.1-py2.py3-none-any.whl (76 kB)\n",
      "Collecting python-slugify\n",
      "  Using cached python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from kaggle) (1.26.6)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from requests->kaggle) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from tqdm->kaggle) (0.4.4)\n",
      "Using legacy 'setup.py install' for kaggle, since package 'wheel' is not installed.\n",
      "Installing collected packages: text-unidecode, tqdm, python-slugify, kaggle\n",
      "    Running setup.py install for kaggle: started\n",
      "    Running setup.py install for kaggle: finished with status 'done'\n",
      "Successfully installed kaggle-1.5.12 python-slugify-5.0.2 text-unidecode-1.3 tqdm-4.62.1\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727863fc",
   "metadata": {},
   "source": [
    "Теперь нам необходимо создать API токен на kaggle по адресу `https://www.kaggle.com/<username>/account` и поместить его в папку .kaggle, расположение которой зависит от ОС:\n",
    "* Для Windows - `C:\\Users\\<Windows-username>\\.kaggle\\kaggle.json`\n",
    "* Для Linux систем - ```~/.kaggle/kaggle.json```\n",
    "\n",
    "### Скачивание и распаковка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bab6acb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\A.Mindset\\internship_ds\\LightFM\\LightFM-Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/228M [00:00<?, ?B/s]\n",
      "  0%|          | 1.00M/228M [00:00<00:33, 7.18MB/s]\n",
      "  3%|3         | 7.00M/228M [00:00<00:08, 26.6MB/s]\n",
      "  5%|5         | 12.0M/228M [00:00<00:06, 35.2MB/s]\n",
      " 11%|#         | 24.0M/228M [00:00<00:03, 64.1MB/s]\n",
      " 14%|#3        | 31.0M/228M [00:00<00:04, 43.7MB/s]\n",
      " 16%|#6        | 37.0M/228M [00:00<00:05, 38.2MB/s]\n",
      " 18%|#8        | 42.0M/228M [00:01<00:06, 32.0MB/s]\n",
      " 20%|##        | 46.0M/228M [00:01<00:06, 29.0MB/s]\n",
      " 22%|##1       | 50.0M/228M [00:01<00:06, 26.8MB/s]\n",
      " 23%|##3       | 53.0M/228M [00:01<00:07, 25.6MB/s]\n",
      " 25%|##4       | 56.0M/228M [00:01<00:07, 24.7MB/s]\n",
      " 26%|##5       | 59.0M/228M [00:02<00:07, 25.1MB/s]\n",
      " 27%|##7       | 62.0M/228M [00:02<00:06, 26.2MB/s]\n",
      " 29%|##8       | 66.0M/228M [00:02<00:05, 28.7MB/s]\n",
      " 30%|###       | 69.0M/228M [00:02<00:06, 26.9MB/s]\n",
      " 32%|###1      | 72.0M/228M [00:02<00:06, 25.3MB/s]\n",
      " 33%|###3      | 76.0M/228M [00:02<00:05, 27.7MB/s]\n",
      " 35%|###4      | 79.0M/228M [00:02<00:05, 27.0MB/s]\n",
      " 36%|###5      | 82.0M/228M [00:02<00:05, 25.9MB/s]\n",
      " 37%|###7      | 85.0M/228M [00:03<00:05, 25.0MB/s]\n",
      " 39%|###8      | 88.0M/228M [00:03<00:06, 24.4MB/s]\n",
      " 40%|###9      | 91.0M/228M [00:03<00:05, 24.0MB/s]\n",
      " 41%|####1     | 94.0M/228M [00:03<00:05, 23.8MB/s]\n",
      " 43%|####2     | 97.0M/228M [00:03<00:05, 23.6MB/s]\n",
      " 44%|####3     | 100M/228M [00:03<00:05, 23.5MB/s] \n",
      " 45%|####5     | 103M/228M [00:03<00:05, 23.4MB/s]\n",
      " 47%|####6     | 106M/228M [00:03<00:05, 23.9MB/s]\n",
      " 48%|####7     | 109M/228M [00:04<00:04, 25.5MB/s]\n",
      " 50%|####9     | 113M/228M [00:04<00:04, 25.0MB/s]\n",
      " 51%|#####     | 116M/228M [00:04<00:04, 26.5MB/s]\n",
      " 52%|#####2    | 119M/228M [00:04<00:04, 25.1MB/s]\n",
      " 54%|#####3    | 122M/228M [00:04<00:04, 25.7MB/s]\n",
      " 55%|#####4    | 125M/228M [00:04<00:04, 25.1MB/s]\n",
      " 56%|#####6    | 128M/228M [00:04<00:04, 24.7MB/s]\n",
      " 58%|#####7    | 131M/228M [00:05<00:04, 24.3MB/s]\n",
      " 59%|#####8    | 134M/228M [00:05<00:04, 24.2MB/s]\n",
      " 60%|######    | 137M/228M [00:05<00:03, 24.0MB/s]\n",
      " 61%|######1   | 140M/228M [00:05<00:03, 24.0MB/s]\n",
      " 63%|######2   | 143M/228M [00:05<00:03, 23.9MB/s]\n",
      " 64%|######4   | 146M/228M [00:05<00:03, 23.9MB/s]\n",
      " 65%|######5   | 149M/228M [00:05<00:03, 25.1MB/s]\n",
      " 67%|######6   | 152M/228M [00:05<00:03, 25.5MB/s]\n",
      " 68%|######8   | 155M/228M [00:06<00:03, 24.5MB/s]\n",
      " 69%|######9   | 158M/228M [00:06<00:02, 26.0MB/s]\n",
      " 71%|#######   | 161M/228M [00:06<00:02, 25.4MB/s]\n",
      " 72%|#######1  | 164M/228M [00:06<00:02, 25.0MB/s]\n",
      " 73%|#######3  | 167M/228M [00:06<00:02, 24.7MB/s]\n",
      " 75%|#######4  | 170M/228M [00:06<00:02, 24.6MB/s]\n",
      " 76%|#######5  | 173M/228M [00:06<00:02, 24.4MB/s]\n",
      " 77%|#######7  | 176M/228M [00:06<00:02, 24.3MB/s]\n",
      " 79%|#######8  | 179M/228M [00:07<00:02, 24.3MB/s]\n",
      " 80%|#######9  | 182M/228M [00:07<00:01, 24.1MB/s]\n",
      " 81%|########1 | 185M/228M [00:07<00:01, 25.0MB/s]\n",
      " 83%|########2 | 188M/228M [00:07<00:01, 23.8MB/s]\n",
      " 84%|########3 | 191M/228M [00:07<00:01, 20.5MB/s]\n",
      " 86%|########5 | 195M/228M [00:07<00:01, 24.5MB/s]\n",
      " 87%|########6 | 198M/228M [00:07<00:01, 25.7MB/s]\n",
      " 88%|########8 | 201M/228M [00:08<00:01, 25.2MB/s]\n",
      " 90%|########9 | 204M/228M [00:08<00:00, 25.7MB/s]\n",
      " 91%|######### | 207M/228M [00:08<00:00, 25.0MB/s]\n",
      " 92%|#########2| 210M/228M [00:08<00:00, 24.5MB/s]\n",
      " 94%|#########3| 213M/228M [00:08<00:00, 24.2MB/s]\n",
      " 95%|#########4| 216M/228M [00:08<00:00, 24.0MB/s]\n",
      " 96%|#########6| 219M/228M [00:08<00:00, 23.9MB/s]\n",
      " 97%|#########7| 222M/228M [00:08<00:00, 23.8MB/s]\n",
      " 99%|#########8| 225M/228M [00:09<00:00, 23.8MB/s]\n",
      "100%|##########| 228M/228M [00:09<00:00, 23.7MB/s]\n",
      "100%|##########| 228M/228M [00:09<00:00, 26.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the-movies-dataset.zip to C:\\A.Mindset\\internship_ds\\LightFM\\LightFM-Dataset\n",
      "\n",
      "C:\\A.Mindset\\internship_ds\\LightFM\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "!mkdir LightFM-Dataset \n",
    "%cd .\\LightFM-Dataset\n",
    "!kaggle datasets download -d rounakbanik/the-movies-dataset\n",
    "zip_file = ZipFile('the-movies-dataset.zip')\n",
    "zip_file.extractall()\n",
    "zip_file.close()\n",
    "os.remove(\"the-movies-dataset.zip\")\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f897b89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-5.2.1-py2.py3-none-any.whl (21.8 MB)\n",
      "Requirement already satisfied: six in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from plotly) (1.16.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.2.1 tenacity-8.0.1\n",
      "Collecting dash\n",
      "  Downloading dash-1.21.0.tar.gz (1.1 MB)\n",
      "Collecting Flask>=1.0.4\n",
      "  Downloading Flask-2.0.1-py3-none-any.whl (94 kB)\n",
      "Collecting flask-compress\n",
      "  Downloading Flask_Compress-1.10.1-py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: plotly in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from dash) (5.2.1)\n",
      "Collecting dash-core-components==1.17.1\n",
      "  Downloading dash_core_components-1.17.1.tar.gz (3.7 MB)\n",
      "Collecting dash-html-components==1.1.4\n",
      "  Downloading dash_html_components-1.1.4.tar.gz (83 kB)\n",
      "Collecting dash-table==4.12.0\n",
      "  Downloading dash_table-4.12.0.tar.gz (1.8 MB)\n",
      "Collecting future\n",
      "  Using cached future-0.18.2.tar.gz (829 kB)\n",
      "Collecting click>=7.1.2\n",
      "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "Collecting Jinja2>=3.0\n",
      "  Using cached Jinja2-3.0.1-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from click>=7.1.2->Flask>=1.0.4->dash) (4.6.4)\n",
      "Requirement already satisfied: colorama in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from click>=7.1.2->Flask>=1.0.4->dash) (0.4.4)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.0.1-cp37-cp37m-win_amd64.whl (14 kB)\n",
      "Collecting brotli\n",
      "  Downloading Brotli-1.0.9-cp37-cp37m-win_amd64.whl (365 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from importlib-metadata->click>=7.1.2->Flask>=1.0.4->dash) (3.10.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from importlib-metadata->click>=7.1.2->Flask>=1.0.4->dash) (3.5.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from plotly->dash) (8.0.1)\n",
      "Requirement already satisfied: six in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from plotly->dash) (1.16.0)\n",
      "Using legacy 'setup.py install' for dash, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for dash-core-components, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for dash-html-components, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for dash-table, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for future, since package 'wheel' is not installed.\n",
      "Installing collected packages: MarkupSafe, Werkzeug, Jinja2, itsdangerous, click, Flask, brotli, future, flask-compress, dash-table, dash-html-components, dash-core-components, dash\n",
      "    Running setup.py install for future: started\n",
      "    Running setup.py install for future: finished with status 'done'\n",
      "    Running setup.py install for dash-table: started\n",
      "    Running setup.py install for dash-table: finished with status 'done'\n",
      "    Running setup.py install for dash-html-components: started\n",
      "    Running setup.py install for dash-html-components: finished with status 'done'\n",
      "    Running setup.py install for dash-core-components: started\n",
      "    Running setup.py install for dash-core-components: finished with status 'done'\n",
      "    Running setup.py install for dash: started\n",
      "    Running setup.py install for dash: finished with status 'done'\n",
      "Successfully installed Flask-2.0.1 Jinja2-3.0.1 MarkupSafe-2.0.1 Werkzeug-2.0.1 brotli-1.0.9 click-8.0.1 dash-1.21.0 dash-core-components-1.17.1 dash-html-components-1.1.4 dash-table-4.12.0 flask-compress-1.10.1 future-0.18.2 itsdangerous-2.0.1\n",
      "Collecting jupyter-dash\n",
      "  Downloading jupyter_dash-0.4.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: requests in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from jupyter-dash) (2.26.0)\n",
      "Requirement already satisfied: ipython in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from jupyter-dash) (7.26.0)\n",
      "Collecting ansi2html\n",
      "  Downloading ansi2html-1.6.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: ipykernel in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from jupyter-dash) (6.2.0)\n",
      "Requirement already satisfied: dash in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from jupyter-dash) (1.21.0)\n",
      "Requirement already satisfied: flask in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from jupyter-dash) (2.0.1)\n",
      "Collecting retrying\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Requirement already satisfied: flask-compress in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from dash->jupyter-dash) (1.10.1)\n",
      "Requirement already satisfied: plotly in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from dash->jupyter-dash) (5.2.1)\n",
      "Requirement already satisfied: dash-core-components==1.17.1 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from dash->jupyter-dash) (1.17.1)\n",
      "Requirement already satisfied: dash-html-components==1.1.4 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from dash->jupyter-dash) (1.1.4)\n",
      "Requirement already satisfied: dash-table==4.12.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from dash->jupyter-dash) (4.12.0)\n",
      "Requirement already satisfied: future in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from dash->jupyter-dash) (0.18.2)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from flask->jupyter-dash) (2.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from flask->jupyter-dash) (3.0.1)\n",
      "Requirement already satisfied: click>=7.1.2 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from flask->jupyter-dash) (8.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from flask->jupyter-dash) (2.0.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from click>=7.1.2->flask->jupyter-dash) (4.6.4)\n",
      "Requirement already satisfied: colorama in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from click>=7.1.2->flask->jupyter-dash) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from Jinja2>=3.0->flask->jupyter-dash) (2.0.1)\n",
      "Requirement already satisfied: brotli in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from flask-compress->dash->jupyter-dash) (1.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from importlib-metadata->click>=7.1.2->flask->jupyter-dash) (3.10.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from importlib-metadata->click>=7.1.2->flask->jupyter-dash) (3.5.0)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from ipykernel->jupyter-dash) (7.0.0)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from ipykernel->jupyter-dash) (1.4.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from ipykernel->jupyter-dash) (6.1)\n",
      "Requirement already satisfied: traitlets<6.0,>=4.1.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from ipykernel->jupyter-dash) (5.0.5)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from ipykernel->jupyter-dash) (0.1.2)\n",
      "Requirement already satisfied: argcomplete>=1.12.3 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from ipykernel->jupyter-dash) (1.12.3)\n",
      "Requirement already satisfied: pygments in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from ipython->jupyter-dash) (2.10.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from ipython->jupyter-dash) (47.1.0)\n",
      "Requirement already satisfied: decorator in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from ipython->jupyter-dash) (5.0.9)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from ipython->jupyter-dash) (0.18.0)\n",
      "Requirement already satisfied: backcall in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from ipython->jupyter-dash) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from ipython->jupyter-dash) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from ipython->jupyter-dash) (3.0.19)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from jedi>=0.16->ipython->jupyter-dash) (0.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from jupyter-client<8.0->ipykernel->jupyter-dash) (22.2.1)\n",
      "Requirement already satisfied: entrypoints in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from jupyter-client<8.0->ipykernel->jupyter-dash) (0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from jupyter-client<8.0->ipykernel->jupyter-dash) (2.8.2)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from jupyter-client<8.0->ipykernel->jupyter-dash) (1.5.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from jupyter-client<8.0->ipykernel->jupyter-dash) (4.7.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel->jupyter-dash) (301)\n",
      "Requirement already satisfied: wcwidth in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-dash) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel->jupyter-dash) (1.16.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from traitlets<6.0,>=4.1.0->ipykernel->jupyter-dash) (0.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from plotly->dash->jupyter-dash) (8.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from requests->jupyter-dash) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from requests->jupyter-dash) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from requests->jupyter-dash) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\a.mindset\\internship_ds\\lightfm\\lightfm-env\\lib\\site-packages (from requests->jupyter-dash) (2021.5.30)\n",
      "Using legacy 'setup.py install' for retrying, since package 'wheel' is not installed.\n",
      "Installing collected packages: retrying, ansi2html, jupyter-dash\n",
      "    Running setup.py install for retrying: started\n",
      "    Running setup.py install for retrying: finished with status 'done'\n",
      "Successfully installed ansi2html-1.6.0 jupyter-dash-0.4.0 retrying-1.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90cfed69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\A.Mindset\\internship_ds\\LightFM\\LightFM-env\\lib\\site-packages\\lightfm\\_lightfm_fast.py:10: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  \"LightFM was compiled without OpenMP support. \"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import itertools\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea1c273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>overview</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Toy Story</th>\n",
       "      <td>862</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jumanji</th>\n",
       "      <td>8844</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grumpier Old Men</th>\n",
       "      <td>15602</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waiting to Exhale</th>\n",
       "      <td>31357</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Father of the Bride Part II</th>\n",
       "      <td>11862</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>رگ خواب</th>\n",
       "      <td>439050</td>\n",
       "      <td>Rising and falling between a man and woman.</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 10751, 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Siglo ng Pagluluwal</th>\n",
       "      <td>111109</td>\n",
       "      <td>An artist struggles to finish his work while a...</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Betrayal</th>\n",
       "      <td>67758</td>\n",
       "      <td>When one of her hits goes wrong, a professiona...</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 18, 'nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Satana likuyushchiy</th>\n",
       "      <td>227506</td>\n",
       "      <td>In a small town live two brothers, one a minis...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Queerama</th>\n",
       "      <td>461257</td>\n",
       "      <td>50 years after decriminalisation of homosexual...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44512 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "original_title                        \n",
       "Toy Story                       862   \n",
       "Jumanji                        8844   \n",
       "Grumpier Old Men              15602   \n",
       "Waiting to Exhale             31357   \n",
       "Father of the Bride Part II   11862   \n",
       "...                             ...   \n",
       "رگ خواب                      439050   \n",
       "Siglo ng Pagluluwal          111109   \n",
       "Betrayal                      67758   \n",
       "Satana likuyushchiy          227506   \n",
       "Queerama                     461257   \n",
       "\n",
       "                                                                      overview  \\\n",
       "original_title                                                                   \n",
       "Toy Story                    Led by Woody, Andy's toys live happily in his ...   \n",
       "Jumanji                      When siblings Judy and Peter discover an encha...   \n",
       "Grumpier Old Men             A family wedding reignites the ancient feud be...   \n",
       "Waiting to Exhale            Cheated on, mistreated and stepped on, the wom...   \n",
       "Father of the Bride Part II  Just when George Banks has recovered from his ...   \n",
       "...                                                                        ...   \n",
       "رگ خواب                            Rising and falling between a man and woman.   \n",
       "Siglo ng Pagluluwal          An artist struggles to finish his work while a...   \n",
       "Betrayal                     When one of her hits goes wrong, a professiona...   \n",
       "Satana likuyushchiy          In a small town live two brothers, one a minis...   \n",
       "Queerama                     50 years after decriminalisation of homosexual...   \n",
       "\n",
       "                                                                        genres  \n",
       "original_title                                                                  \n",
       "Toy Story                    [{'id': 16, 'name': 'Animation'}, {'id': 35, '...  \n",
       "Jumanji                      [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...  \n",
       "Grumpier Old Men             [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...  \n",
       "Waiting to Exhale            [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...  \n",
       "Father of the Bride Part II                     [{'id': 35, 'name': 'Comedy'}]  \n",
       "...                                                                        ...  \n",
       "رگ خواب                      [{'id': 18, 'name': 'Drama'}, {'id': 10751, 'n...  \n",
       "Siglo ng Pagluluwal                              [{'id': 18, 'name': 'Drama'}]  \n",
       "Betrayal                     [{'id': 28, 'name': 'Action'}, {'id': 18, 'nam...  \n",
       "Satana likuyushchiy                                                         []  \n",
       "Queerama                                                                    []  \n",
       "\n",
       "[44512 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_metadata = pd.read_csv('LightFM-Dataset/movies_metadata.csv', low_memory=False)[['id','original_title','overview','genres']].set_index('original_title').dropna()\n",
    "movie_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20941603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>858</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1221</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1246</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26024284</th>\n",
       "      <td>270896</td>\n",
       "      <td>58559</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26024285</th>\n",
       "      <td>270896</td>\n",
       "      <td>60069</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26024286</th>\n",
       "      <td>270896</td>\n",
       "      <td>63082</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26024287</th>\n",
       "      <td>270896</td>\n",
       "      <td>64957</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26024288</th>\n",
       "      <td>270896</td>\n",
       "      <td>71878</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26024289 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating\n",
       "0              1      110     1.0\n",
       "1              1      147     4.5\n",
       "2              1      858     5.0\n",
       "3              1     1221     5.0\n",
       "4              1     1246     5.0\n",
       "...          ...      ...     ...\n",
       "26024284  270896    58559     5.0\n",
       "26024285  270896    60069     5.0\n",
       "26024286  270896    63082     4.5\n",
       "26024287  270896    64957     4.5\n",
       "26024288  270896    71878     2.0\n",
       "\n",
       "[26024289 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_dataset = pd.read_csv('LightFM-Dataset/ratings.csv', low_memory=False)[['userId','movieId','rating']].dropna()\n",
    "rating_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6df95fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape User-Ratings unfiltered:\t(26024289, 3)\n",
      "Shape User-Ratings filtered:\t(6655935, 3)\n"
     ]
    }
   ],
   "source": [
    "# Убираем фильмы и пользователей с малым количеством отзывов\n",
    "filter_movies = (rating_dataset['movieId'].value_counts()>10000)\n",
    "filter_movies = filter_movies[filter_movies].index.tolist()\n",
    "\n",
    "filter_users = (rating_dataset['userId'].value_counts()>200)\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "rating_dataset_filtered = rating_dataset[(rating_dataset['movieId'].isin(filter_movies)) & (rating_dataset['userId'].isin(filter_users))]\n",
    "del filter_movies, filter_users\n",
    "print('Shape User-Ratings unfiltered:\\t{}'.format(rating_dataset.shape))\n",
    "print('Shape User-Ratings filtered:\\t{}'.format(rating_dataset_filtered.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d16493dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>11</td>\n",
       "      <td>110</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>11</td>\n",
       "      <td>165</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>11</td>\n",
       "      <td>231</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>11</td>\n",
       "      <td>260</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>11</td>\n",
       "      <td>296</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>11</td>\n",
       "      <td>318</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>11</td>\n",
       "      <td>344</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId  rating\n",
       "414      11       32     3.5\n",
       "415      11       34     4.0\n",
       "416      11       47     3.5\n",
       "417      11      110     3.5\n",
       "418      11      165     3.5\n",
       "419      11      231     2.5\n",
       "420      11      260     3.0\n",
       "421      11      296     4.0\n",
       "422      11      318     4.5\n",
       "423      11      344     3.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_dataset_filtered.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f2c033b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16087</td>\n",
       "      <td>150</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57772</td>\n",
       "      <td>185</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>205780</td>\n",
       "      <td>1250</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29789</td>\n",
       "      <td>780</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140746</td>\n",
       "      <td>1247</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>226886</td>\n",
       "      <td>3481</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>99350</td>\n",
       "      <td>1923</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>143399</td>\n",
       "      <td>95</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>146783</td>\n",
       "      <td>5991</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38495</td>\n",
       "      <td>44191</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0   16087      150     1.5\n",
       "1   57772      185     4.0\n",
       "2  205780     1250     5.0\n",
       "3   29789      780     4.0\n",
       "4  140746     1247     3.5\n",
       "5  226886     3481     3.5\n",
       "6   99350     1923     4.0\n",
       "7  143399       95     2.5\n",
       "8  146783     5991     5.0\n",
       "9   38495    44191     4.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_dataset_filtered_shuffled = rating_dataset_filtered.sample(frac=1).reset_index(drop=True)\n",
    "rating_dataset_filtered_shuffled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3f23d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "rating_dataset_train = rating_dataset_filtered_shuffled[:-n]\n",
    "rating_dataset_test = rating_dataset_filtered_shuffled[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f356e82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16087</td>\n",
       "      <td>150</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57772</td>\n",
       "      <td>185</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>205780</td>\n",
       "      <td>1250</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29789</td>\n",
       "      <td>780</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140746</td>\n",
       "      <td>1247</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5655930</th>\n",
       "      <td>256652</td>\n",
       "      <td>235</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5655931</th>\n",
       "      <td>201405</td>\n",
       "      <td>4014</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5655932</th>\n",
       "      <td>164071</td>\n",
       "      <td>924</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5655933</th>\n",
       "      <td>159676</td>\n",
       "      <td>2700</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5655934</th>\n",
       "      <td>203372</td>\n",
       "      <td>7438</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5655935 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  movieId  rating\n",
       "0         16087      150     1.5\n",
       "1         57772      185     4.0\n",
       "2        205780     1250     5.0\n",
       "3         29789      780     4.0\n",
       "4        140746     1247     3.5\n",
       "...         ...      ...     ...\n",
       "5655930  256652      235     3.0\n",
       "5655931  201405     4014     4.0\n",
       "5655932  164071      924     2.5\n",
       "5655933  159676     2700     3.5\n",
       "5655934  203372     7438     4.0\n",
       "\n",
       "[5655935 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83456c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape User-Movie-Matrix:\t(32811, 636)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>99114</th>\n",
       "      <th>106782</th>\n",
       "      <th>109487</th>\n",
       "      <th>112556</th>\n",
       "      <th>112852</th>\n",
       "      <th>116797</th>\n",
       "      <th>122882</th>\n",
       "      <th>122886</th>\n",
       "      <th>134130</th>\n",
       "      <th>134853</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19084</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170372</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 636 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       2       3       5       6       7       10      11      \\\n",
       "userId                                                                    \n",
       "1602        NaN     NaN     3.0     3.0     NaN     NaN     NaN     NaN   \n",
       "19084       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "170372      3.0     4.0     NaN     NaN     4.5     NaN     4.0     NaN   \n",
       "\n",
       "movieId  16      17      ...  99114   106782  109487  112556  112852  116797  \\\n",
       "userId                   ...                                                   \n",
       "1602        4.0     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "19084       NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "170372      NaN     NaN  ...     NaN     NaN     NaN     NaN     4.5     NaN   \n",
       "\n",
       "movieId  122882  122886  134130  134853  \n",
       "userId                                   \n",
       "1602        NaN     NaN     NaN     NaN  \n",
       "19084       NaN     NaN     NaN     NaN  \n",
       "170372      2.0     NaN     NaN     3.0  \n",
       "\n",
       "[3 rows x 636 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Создадим User-Movie-matrix\n",
    "user_movie_matrix = rating_dataset_train.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "print('Shape User-Movie-Matrix:\\t{}'.format(user_movie_matrix.shape))\n",
    "user_movie_matrix.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5edce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создадим маппинг для пользователей и фильмов\n",
    "user_id_mapping = {id:i for i, id in enumerate(rating_dataset_filtered['userId'].unique())}\n",
    "movie_id_mapping = {id:i for i, id in enumerate(rating_dataset_filtered['movieId'].unique())}\n",
    "#Применим его к обучающему и тренировочному набору\n",
    "train_user_data = rating_dataset_train['userId'].map(user_id_mapping)\n",
    "train_movie_data = rating_dataset_train['movieId'].map(movie_id_mapping)\n",
    "\n",
    "test_user_data = rating_dataset_test['userId'].map(user_id_mapping)\n",
    "test_movie_data = rating_dataset_test['movieId'].map(movie_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "058a2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создадим разреженную матрицу рейтинга\n",
    "shape = (len(user_id_mapping), len(movie_id_mapping))\n",
    "train_matrix = coo_matrix((rating_dataset_train['rating'].values, (train_user_data.astype(int), train_movie_data.astype(int))), shape=shape)\n",
    "test_matrix = coo_matrix((rating_dataset_test['rating'].values, (test_user_data.astype(int), test_movie_data.astype(int))), shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d72e6fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9min 4s ± 12.5 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "#Создадим модель LightFM и обучим ем\n",
    "model = LightFM(loss='warp')\n",
    "%timeit model.fit(train_matrix, epochs=30, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a886beaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train precision at k=20:\t0.7917\n",
      "Test precision at k=20:\t\t0.1182\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "print('Train precision at k={}:\\t{:.4f}'.format(k, precision_at_k(model, train_matrix, k=k).mean()))\n",
    "print('Test precision at k={}:\\t\\t{:.4f}'.format(k, precision_at_k(model, test_matrix, k=k).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71740081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train precision at k=20:\t0.9580\n",
      "Test precision at k=20:\t\t0.0138\n"
     ]
    }
   ],
   "source": [
    "#Старая версия модели с урезанным датасетом показывала подобные результаты\n",
    "k = 20\n",
    "print('Train precision at k={}:\\t{:.4f}'.format(k, precision_at_k(model, train_matrix, k=k).mean()))\n",
    "print('Test precision at k={}:\\t\\t{:.4f}'.format(k, precision_at_k(model, test_matrix, k=k).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881f43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LightFM-env",
   "language": "python",
   "name": "lightfm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
