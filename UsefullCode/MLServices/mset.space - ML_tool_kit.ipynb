{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оглавление\n",
    "1. Обработка голоса и текста использованием ML  \n",
    "  Блокнот - Speechpad.ru  \n",
    "  Yandex SpeechKit  \n",
    "  Gpt2 https://habr.com/ru/post/440564/\n",
    "  Gpt3 https://habr.com/ru/post/514698/\n",
    "2. Машинное обучение и обработка видео.  \n",
    "Flow-edge Новый алгоритм дополнения видео, который убирает водяные знаки и целые движущиеся объекты, а также расширяет поле зрения видео с учетом движения кадра.  https://github.com/vt-vl-lab/FGVC   https://habr.com/en/post/522156/\n",
    "FrankMocap Facebook AI представил систему создания 3D-мокапов рук и тела на основе анализа монокулярного видео. https://habr.com/en/post/522156/  \n",
    "Колоризация черно-белых видео с помощью машинного обучения. https://github.com/jantic/DeOldify\n",
    "3. Умные Telegram боты.    \n",
    "  Создание обучаемого бота с помощью сервиса Dialogflow(ИИ для общения с возможностью обучения) https://habr.com/ru/post/342762/\n",
    "  Создание телеграмм бота для интернет магазинов, принимающего изображение чека/свидетельства об отправки посылки по почте и распознающий неободимые строки из текста. Например трэк номер, номерз заказа, время отправки, Qr код. Затем происходит сортировка полученных данных.\n",
    "4. Анализ текста и изображения с помощью ML.  \n",
    "Amazon Textract https://youtu.be/8kobcRynTTA\n",
    "Оптическое распознавание символов Optical character recognition Tesseract https://youtu.be/UPjTYorn59g  \n",
    "MLKit  \n",
    "Apple vision  \n",
    "Превращение сжатого изображения ввиде пикселей в изображение с высоким разрешением. SREZ, Depixelizer https://github.com/david-gpu/srez https://github.com/tg-bomze/Face-Depixelizer  \n",
    "GAN Generative adversarial network with images https://www.youtube.com/watch?v=lfltadp-IM4&feature=youtu.be  \n",
    "https://github.com/chaofengc/PSFRGAN\n",
    "5. Парковочные места.  \n",
    "Поиск свободного парковочного места. https://www.youtube.com/watch?v=y1M5dNkvCJc  \n",
    "6. Формирование playlist и создание музыки с помощью ML.  \n",
    "podbot.ai  \n",
    "vokaloid https://clck.ru/TKH3p\n",
    "7. Строительство объектов.\n",
    "Autodesk Construction IQ. Construction IQ (ранее известный как Project IQ) – интеллектуальный помощник для проектов строительства в которых применяется платформа Autodesk BIM 360. Использующий методы машинного обучения, Construction IQ собирает и анализирует данные о качестве и безопасности строительных объектов, возможных рисках проекта. https://habr.com/ru/post/466165/ (https://youtu.be/kn92fc0K9fU)  \n",
    "8. Генерация контента\n",
    "Pages by Headlime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка голоса и текста использованием ML \n",
    "### Блокнот - Speechpad.ru  \n",
    "Основная задача: Speechpad — бесплатный сервис для голосового ввода текста. Доступен в трех форматах:  \n",
    "1) онлайн-сервис;  \n",
    "2) браузерное расширение — с его помощью можно вводить текст в любое поле для ввода;  \n",
    "3) мобильное приложение для Android и iOS.  \n",
    "У сервиса также есть платные функции. Их два вида:  \n",
    "дополнительные (расширенные). Включают в себя голосовой ввод в режиме интеграции с OS Linux и Windows, а также транскрибирование аудиофайлов длиной более 15 минут;  \n",
    "премиум. Пакетное транскрибирование аудио и видео (больше двух файлов).  \n",
    "В процессе работы можно настроить:  \n",
    "1) настроить язык голосового ввода. Базово с списке доступно 14 языков (среди них русский, украинский, английский, немецкий). Если нужен другой язык, необходимо зарегистрироваться в сервисе. После этого в личном кабинете появится возможность добавить этот язык (если для него поддерживается распознавание речи);  \n",
    "2) активировать опцию «Включить команды». Если вы авторизованы в личном кабинете, вы можете добавлять голосовые команды и использовать их при надиктовке текста. Например, удалить последний распознанный фрагмент текста;  \n",
    "3) отключить управление заглавными буквами Google. По умолчанию в речи распознается начало предложений и автоматически проставляются заглавные буквы. Вы можете отключить эту опцию и самостоятельно редактировать предложения.  \n",
    "\n",
    "Похожие сервисы:VoiceNote https://voicenote.in/  \n",
    "Voice Notepad https://dictation.io/speech  \n",
    "Speechtexter.com https://www.speechtexter.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yandex speechkit  \n",
    "Это публичный API для распознавания речи, который могут использовать разработчики под Android и iOS.\n",
    "Принцип работы:  \n",
    "Акустическая модель все так же принимает на вход звук, а на выходе дает распределение вероятностей по сенонам. Теперь рассмотрим, что конкретно подается на вход. Как мы говорили, звук нарезается участками по 25 мс («фреймами»). Как правило, шаг нарезки составляет 10 мс, так что соседние фреймы частично пересекаются. Понятно, что «сырой» звук — амплитуда колебаний по времени — не самая информативная форма представления акустического сигнала. Спектр этого сигнала — уже гораздо лучше. На практике обычно используется логарифмированный и отмасштабированный спектр, что соответствует закономерностям человеческого слухового восприятия (Mel-преобразование). Полученные величины подвергаются дискретному косинусному преобразованию (DCT), и в результате получается MFCC — Mel Frequency Cepstral Coefficients. (Слово Cepstral получено перестановкой букв в Spectral, что отражает наличие дополнительного DCT). MFCC — это вектор из 13 (обычно) вещественных чисел. Они могут использоваться как вход акустической модели «в сыром виде», но чаще подвергаются множеству дополнительных преобразований  \n",
    "\n",
    "Для тренировки используются алгоритмы семейства Expectation-Maximization, такие, как алгоритм Баума-Велша. Суть алгоритмов такого рода — в чередовании двух шагов: на шаге Expectation имеющаяся модель используется для вычисления матожидания функции правдоподобия, на шаге Maximization параметры модели изменяются таким образом, чтобы максимизировать эту оценку. На ранних этапах тренировки используются простые акустические модели: на вход даются простые MFCC features, фонемы рассматриваются вне контекстной зависимости, для моделирования вероятности эмиссии в HMM используется смесь гауссиан с диагональными матрицами ковариаций (Diagonal GMMs — Gaussian Mixture Models). Результаты каждой предыдущей акустической модели являются стартовой точкой для тренировки более сложной модели, с более сложным входом, выходом или функцией распределения вероятности эмиссии. Существует множество способов улучшения акустической модели, однако наиболее значительный эффект имеет переход от GMM-модели к DNN (Deep Neural Network), что повышает качество распознавания практически в два раза. Нейронные сети лишены многих ограничений, характерных для гауссовых смесей, и обладают лучшей обобщающей способностью. Кроме того, акустические модели на нейронных сетях более устойчивы к шуму и обладают лучшим быстродействием.  \n",
    "\n",
    "Нейронная сеть для акустического моделирования тренируется в несколько этапов. Для инициализации нейросети используется стек из ограниченных машин Больцмана (Restricted Boltzmann Machines, RBM). RBM — это стохастическая нейросеть, которая тренируется без учителя. Хотя выученные ей веса нельзя напрямую использовать для различения между классами акустических событий, они детально отражают структуру речи. Можно относиться к RBM как к механизму извлечения признаков (feature extractor) — полученная генеративная модель оказывается отличной стартовой точкой для построения дискриминативной модели. Дискриминативная модель тренируется с использованием классического алгоритма обратного распространения ошибки, при этом применяется ряд технических приемов, улучшающих сходимость и предотвращающих переобучение (overfitting). В итоге на входе нейросети — несколько фреймов MFCC-features (центральный фрейм подлежит классификации, остальные образуют контекст), на выходе — около 4000 нейронов, соответствующих различным сенонам. Эта нейросеть используется как акустическая модель в production-системе.\n",
    "\n",
    "Использование: Автоматизация CALL-центров, телемаркетинговые кампании, управление приложениями.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](3.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2\n",
    "GPT-2 - это детище всемирно известной OpenAI. И это генератор реалистичных текстов на любую заданную тематику. Обученная на 8 миллионах новостных сайтов, нейросеть способна имитировать различных авторов и дописывать текст, ориентируясь на пару начальных строк. При этом стиль повествования будет соответствовать исходнику, а результат генерации текста каждый раз будет уникальным. Она способна по одной вводной фразе сочинить осмысленную статью. Кроме того, нейросеть можно использовать для задач машинного перевода, ответов на вопросы и распознавания речи.  \n",
    "Цель создания GPT-2 была довольно простой: нейросеть должна предсказывать следующее слово, учитывая все предыдущие слова в тексте. Но поскольку обучающий датасет оказался очень разнообразным, возможности GPT-2 нашли применение и в других областях. \n",
    "\n",
    "GPT-2 — это улучшенная версия языковой модели GPT, в основе которой лежит нейросеть Transformator. Для обучения GPT-2 использовался набор данных, состоящий из 8 миллионов веб-страниц объёмом 40 ГБ. Модель имеет 1.5 миллиарда параметров, что в 10 раз больше, чем у GPT.  \n",
    "GPT-2 может генерировать синтетические образцы текста, по качеству близкие к человеческим. Нейросеть превосходит другие языковые модели, обученные на конкретных примерах (статьях из Википедии, новостях или книгах), без необходимости использования этих наборов данных для переобучения. \n",
    "\n",
    "Простой пример:  GPT 2 приспосабливается к стилю и содержанию текста, что позволяет ей генерировать реалистичные отрывки, продолжающие исходные фразы.\n",
    "\n",
    "Новая глава «Властелина Колец» (с первой попытки)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2 достигает одних из самых высоких результатов в определённых задачах языкового моделирования. Нейросеть не переобучалась на конкретных данных для какой-либо области и оценивалась на них в своём исходном состоянии — это называется zero-shot обучение. GPT-2 превосходит предметно-ориентированные модели при оценке на тех же наборах данных.  \n",
    "GPT-2 справляется и с машинным переводом.  \n",
    "А ещё, не так давно с её помощью был разработан инструмент для автозаполнения кода в текстовых редакторах TabNine. Он обучался примерно на двух миллионах файлов с GitHub и доступен для бесплатного использования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](5.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-3\n",
    "GPT-3(Generative Pre-trained Transformer 3)—третье поколение алгоритма обработки естественного языка от OpenAI.  \n",
    "На сентябрь 2020 года это самая крупная и продвинутая языковая модель в мире.  \n",
    "Модель, по заявлению разработчиков, может быть использована для решения «любых задач на английском языке».  \n",
    "Алгоритм работает по принципу автодополнения: вы вводите начало текста, а программа генерирует наиболее вероятное его продолжение. \n",
    "Процесс обучения:\n",
    "На ввод модели мы подаем один пример (отображаем только признаки) и просим ее предсказать следующее слово предложения.т  \n",
    "Поначалу предсказания модели будут ошибочны. Мы подсчитываем ошибку в предсказании и обновляем модель до тех пор, пока предсказания не улучшатся.  \n",
    "И так несколько миллионов раз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](6.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможности и примеры использования:  \n",
    "1) Генерация статей.\n",
    "8 сентября 2020 британское издание The Guardian опубликовало у себя заметку, написанную при помощи GPT-3. \n",
    "Редакция «попросила» модель написать эссе о том, почему люди не должны бояться роботов. \n",
    "Лиам Порр предоставил редакции 8 сгенерированных GPT-3 вариантов эссе, из которых редакторы издания собрали итоговый текст.  \n",
    "2) Ответы на вопросы.\n",
    "В октябре 2020 в разделе сайта Reddit, где пользователи задают друг другу вопросы, \n",
    "появился бот, который в течение недели опубликовал более 1000 развёрнутых ответов на эти вопросы.  \n",
    "8 ноября 2020 биолог Александр Панчин опубликовал свой диалог с GPT-3 о старении, лженауке и смысле жизни.   \n",
    "Изначально диалог вёлся на английском языке через OpenAI API Playground,   \n",
    "но Панчин перевёл диалог на русский язык и отредактировал его (изначальная версия на английском сохранилась).  \n",
    "Фрагмент из диалога:  \n",
    "Панчин: Если учёный хочет найти лекарство от старости, какие гены он должен изучить в первую очередь?  \n",
    "GPT-3: Если учёный хочет найти лекарство от старости, лучшими генами для изучения были бы SIRT1, FOXO3 и BDNF.  \n",
    "Биолог пояснил, что если бы спросили его, то он бы тоже упомянул ген SIRT1, а про остальные два он знает меньше,  \n",
    "но после изучения литературы согласился с тем, что FOXO3 и BDNF — перспективные гены.  \n",
    "3) Чат-бот"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Машинное обучение и обработка видео.\n",
    "### Flow-edge\n",
    "Новый алгоритм дополнения видео, который убирает водяные знаки и целые движущиеся объекты,   \n",
    "а также расширяет поле зрения видео с учетом движения кадра.   \n",
    "Как и другие похожие алгоритмы, сначала он определяет и восстанавливает края движущихся объектов.  \n",
    "Дорисованные границы в таком случае не выглядят естественно в сцене.   \n",
    "Особенность метода в том, что он отслеживает пять типов не локально соседствующих пикселей, то есть, находящихся на разных кадрах, \n",
    "затем определяет, каким из них можно доверять, и использует эти данные для восстановления недостающих областей.  \n",
    "В результате видео получается более плавным.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](7.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FrankMocap  \n",
    "Все, кто работал с 3D, знают, что для создания качественных моделей нужно различное дорогое фотооборудование и умение пользоваться сложным софтом. Но алгоритмы машинного обучения активно используются, чтобы упростить работу художников в этой области.\n",
    "\n",
    "Facebook AI представил систему создания 3D-мокапов рук и тела на основе анализа монокулярного видео. Захват движений работает в режиме, близком к реальному времени (9,5 кадра в секунду), и создает трехмерные изображения тела и рук в виде унифицированной параметрической модели. В отличии от других существующих подходов, этот позволяет одновременно захватывать и жесты рук, и движения всего тела."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](8.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeOldify  \n",
    "Это модель на основе глубокого обучения. В частности, я совместил следующие подходы:\n",
    "\n",
    "    Self-Attention GAN. Единственное, что в качестве генератора используется предобученная Unet и я просто изменил её для спектральной нормализации и собственно, механизма Self-Attention. Это довольно простая модификация. Скажу вам, что разница поразительная по сравнению с предыдущей версией Wasserstein GAN, которую я пытался заставить работать. Мне нравилась теория Wasserstein GAN, но на практике она не работает. Но я просто влюбился в сети Self-Attention GAN.\n",
    "    Структура обучения наподобие прогрессивного роста GAN (но не в точности такая). Разница в том, что количество слоёв остаётся постоянным: я просто изменил размер входных данных и скорректировал скорость обучения, чтобы переходы между размерами проходили успешно. Похоже, она выдаёт такой же конечный результат, но быстрее обучается, сама стабильнее и лучше выполняет обобщение.\n",
    "    Правило TTUR (Two Time-Scale Update Rule). Здесь довольно понятно: просто итерации один к одному генератора/дискриминатора (критика) и более высокая скорость обучения дискриминатора.\n",
    "    Функция потери генератора состоит из двух частей: одна из них является основной функцией Perceptual Loss (или Feature Loss) на базе VGG16 — она просто подталкивает модель генератора для репликации входного изображения. Вторая часть — оценка потерь от дискриминатора (критика). Для любопытных: только функции Perceptual Loss недостаточно для хорошего результата. Она имеет тенденцию просто поощрять кучу коричневого/зелёного/синего — ну понимаете, обманывая тест, в чём действительно хороши нейронные сети! Ключевой момент в том, что GAN по сути сами изучают для вас функцию потерь, что на самом деле является одним большим шагом на пути к тому идеалу, к которому мы стремимся в машинном обучении. И конечно же, результаты значительно улучшатся, когда машина сама обучается тому, что вы ранее кодировали вручную. Безусловно, здесь это имеет место.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](10.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Умные телеграмм боты. \n",
    "### Создание обучаемого бота с помощью сервиса Dialogflow(ИИ для общения с возможностью обучения)  \n",
    "Dialogflow — это сервис, позволяющий создавать чат-ботов для разных платформ и языков на разных устройствах.  \n",
    "Dialogflow умеет сопоставить фразу пользователя на естественном языке (и на русском тоже) с некоторым «неязыковым» значением (называемым intent) и что-нибудь ответить. Вдобавок он еще и держит контекст диалога, чтобы на следующую фразу можно было среагировать в контексте предыдущих реплик.\n",
    "Создадим бота."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](13.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Инструмент довольно прост в управлении, и еще хранит всю статистику запросов, чтобы можно было в один клик дообучать агента новыми интентами или пополнять существующие. Собственно так и происходит обучение — вы просто показываете примеры запросов, которые относятся к тому или иному интенту в вашем агенте, а Dialogflow автоматически строит модель и все лучше и лучше понимает пользователя. Также он может выделить из фразы какие-то сущности, например даты или города, если вам это необходимо для выполнения какой-то функции.\n",
    "\n",
    "Реагируем на реплики\n",
    "Если нажать на плюсик рядом со словом Intents в левом меню, то можно добавить новый интент и указать для него список фраз, на которые нужно что-то ответить. В списке Training phrases добавьте те фразы, которые скорее всего будет произносить пользователь. Чем их больше, тем лучше.\n",
    "Dialogflow может выстраивать интенты в цепочки, чтобы ваш навык мог реагировать правильным образом на фразы, сказанные в контексте беседы. Чтобы это сделать, просто добавьте интент к другому интенту. Для этого перейдите на список интентов и наведите мышь на один из них. Справа появится еле заметная надпись Add follow up intent. Нажмите на нее и добавьте интент, который будет работать в контексте предыдущего. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, Dialogflow бот может взять на себя различные обязанности. Например, сбор информации о пользователе, заказе и отправку на вашу службу только готового результата. Для стабильной работы например интернет магазина останется только настроить отправку WebHook на ваш сервер, который отреагирует и реализует доставку. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](15.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Анализ текста и изображения с помощью ML.\n",
    "### Amazon Textract\n",
    "Amazon Textract — это полностью управляемая служба машинного обучения, которая автоматически извлекает печатный текст, почерк и другие данные из отсканированных документов, которые выходят за рамки простого оптического распознавания символов (OCR) для идентификации, понимания и извлечения данных из форм и таблиц.\n",
    "Чтобы преодолеть эти ручные процессы, Textract использует машинное обучение для мгновенного чтения и обработки любого типа документа, точного извлечения печатного текста, почерка, форм, таблиц и других данных без необходимости каких-либо ручных усилий или пользовательского кода.\n",
    "Использование кейсов Создание индексов интеллектуального поиска Извлекайте структурированные данные из документов и создавайте интеллектуальный индекс, позволяющий быстро искать миллионы финансовых отчетов. Например, ипотечная компания может использовать Amazon Textract для обработки миллионов отсканированных кредитных заявок в течение нескольких часов и иметь извлеченные данные, индексированные в Amazon Elasticsearch. Это позволит им создавать опыт поиска, как \"поиск кредитных заявок, где заявитель имя Джон Доу\", или \"поиск контрактов, где процентная ставка составляет 2 процента\". Создание автоматизированных рабочих процессов обработки документов Amazon Textract может предоставить входные данные, необходимые для автоматической обработки форм без вмешательства человека. Например, банки могут автоматизировать кредитные заявки с помощью Amazon Textract. Информация, содержащаяся в документе, может быть использована для инициирования всех необходимых проверок и кредитных проверок для утверждения кредита, с тем чтобы клиенты могли получить мгновенные результаты их применения, а не ждать несколько дней для ручного рассмотрения и проверки. Поддержание соответствия в архивах документов Поскольку Amazon Textract автоматически идентифицирует типы данных и формирует метки, легко поддерживать соответствие требованиям контроля над информацией. Например, страховщик может использовать Amazon Textract для подачи рабочего процесса, который автоматически отредактировать личную информацию (PII) для их рассмотрения, прежде чем архивировать формы претензий, автоматически признавая важные пары ключевых значений, которые требуют защиты.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](16.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tesseract Tesseract\n",
    "Optical character recognition Tesseract Tesseract (с англ. — «тессеракт», от др.-греч. τέσσαρες ἀκτῖνες — «четыре луча») — свободная компьютерная программа для распознавания текстов, разрабатывавшаяся Hewlett-Packard с середины 1980-х по середину 1990-х, а затем 10 лет «пролежавшая на полке». В августе 2006 г. Google купил её и открыл исходные тексты под лицензией Apache 2.0.\n",
    "Языковые модели и словари Tesseract\n",
    "Для распознавания текста на конкретном языке Tesseract использует языковые модели и словари. Языковая модель содержит в себе значения параметров модели нейронной сети и другие данные обучения. Например, языковая модель для английского языка хранится в файле eng.traineddata. Пользователь может создать свой список слов для Tesseract так, чтобы Tesseract мог научиться их распознавать.\n",
    "Tesseract позволяет расширять стандартный словарь для любого поддерживаемого языка добавлением собственных слов либо обучить языковую модель полностью заменив слова стандартного словаря своими словами.\n",
    "Tesseract использует специальные файлы .dawg для различных категорий слов в словаре. Например, файл .word-dawg используется для основных слов словаря, а файл freq-dawg — для наиболее часто встречающихся слов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Kit\n",
    "Что такое ML Kit?\n",
    "Это мобильный SDK от Google, который позволяет использовать легко использовать машинное обучение на устройствах с Android и iOS. Необязательно быть экспертом в ML или в искусственном интеллекте, потому что в несколько строчек кода можно реализовать очень сложные вещи. Более того, необязательно знать, как работают нейронные сети или оптимизация моделей.\n",
    "Что же может ML Kit?\n",
    "Базовые возможности достаточно широкие. Например, можно распознавать текст, лица, находить и отслеживать объекты, создавать метки для изображений и собственные модели классификации, сканировать штрих-коды и QR-метки.\n",
    "Распознавание QR-кодов мы уже использовали в приложении Яндекс.Денег.\n",
    "Ещё в ML Kit есть\n",
    "Распознавание ориентиров;\n",
    "Определение языка, на котором написан текст;\n",
    "Перевод текстов на устройстве;\n",
    "Быстрый ответ на письмо или сообщение.\n",
    "Кроме огромного количества методов из коробки, есть поддержка кастомных моделей, что практически дает безграничные возможности — например, можно раскрашивать черно-белые фотографии и делать их цветными.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](18.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple vision  \n",
    "VisionKit продукт от компании Apple. По функционалу очень похож на предыдущий набор сервисов от google. Пример сканирования изображения и распознавания текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](19.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SREZ, Depixelizer\n",
    "Превращение сжатого изображения ввиде пикселей в изображение с высоким разрешением. SREZ, Depixelizer\n",
    "Face-depixelizer-это своего рода фронтэнд для движка PULSE, который базируется на нейросети StyleGAN (генерирует лица со случайными чертами).\n",
    "Нейросеть принимает изображение лица в низком разрешении, подбирает фотографию, которая при пикселизации даст наиболее подходящий результат, и подгоняет её под пропорции исходного файла."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](21.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN\n",
    "Генеративно-состязательная сеть (англ. Generative adversarial network, сокращённо GAN) — алгоритм машинного обучения без учителя. Aрхитектура, состоящая из генератора и дискриминатора, настроенных на работу друг против друга. Отсюда GAN и получила название генеративно-созтязательная. В случае работы с изображениями, во всем остальном — это сверточная нейронная сеть.\n",
    "\n",
    "Между тем, генератор создает новые изображения, которые он передает дискриминатору. Он делает это в надежде, что они будут приняты подлинными, хотя являются поддельными. Цель генератора состоит в том, чтобы генерировать рукописные цифры, которые будут пропущены дискриминатором. Цель дискриминатора — определить, является ли изображение подлинным.\n",
    "\n",
    "Шаги, которые проходит GAN:  \n",
    " Генератор получает рандомное число и возвращает изображение.  \n",
    " Это сгенерированное изображение подается в дискриминатор наряду с потоком изображений, взятых из фактического набора данных.  \n",
    " Дискриминатор принимает как реальные, так и поддельные изображения и возвращает вероятности, числа от 0 до 1, причем 1 представляет собой подлинное изображение и 0 представляет фальшивое.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](23.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Парковочные места  \n",
    "### Поиск свободного парковочного места."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](24.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постановка необходимых задач и решение:\n",
    "Распознавание парковочных мест.\n",
    "Данная задача решается с помощью предполажения, что машины, долго находящиеся в кадре и не двигающиеся с места, стоят как раз именно на парковочном месте. Т.е. задача сводится к распознаванию машин.\n",
    "\n",
    "Распознаём машины\n",
    "\n",
    "Можно использовать подход с глубоким обучением вроде Mask R-CNN, Faster R-CNN или YOLO, который совмещает в себе точность CNN и набор технических хитростей, сильно повышающих скорость распознавания. Такие модели будут работать относительно быстро (на GPU), если у нас есть много данных для обучения модели.\n",
    "\n",
    "Для обучения Mask R-CNN нам нужно много изображений объектов, которые мы хотим распознавать. Для этого используем популярный датасет СОСО(сокращение для Common Objects In Context), в котором есть изображения, аннотированные масками объектов. В этом датасете находится более 12 000 изображений с уже размеченными машинами.\n",
    "Чтобы найти незанятые места, нужно всего лишь проверить каждую строку в массиве. Если все числа близки к нулю, то скорее всего место свободно!\n",
    "\n",
    "Как только мы убедимся, что место, где стояла машина, остаётся свободным в течение нескольких кадров, можно отсылать сообщение!  \n",
    "Отправляем SMS\n",
    "\n",
    "Последняя задача — отправка SMS-уведомления при появлении свободного парковочного места.\n",
    "\n",
    "Отправить сообщение из Python очень легко, если использовать Twilio. Twilio — это популярный API, который позволяет отправлять SMS из практически любого языка программирования с помощью всего нескольких строк кода. Конечно, если вы предпочитаете другой сервис, то можете использовать и его. Я никак не связан с Twilio, просто это первое, что приходит на ум.\n",
    "\n",
    "Чтобы использовать Twilio, зарегистрируйте пробный аккаунт, создайте номер телефона Twilio и получите аутентификационные данные аккаунта. Затем установите клиентскую библиотеку:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](25.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Формирование playlist и споздание музыки с помощью ML.\n",
    "PodBot.AI\n",
    "Создан Нимо Ротемом и Вилли Ариски для демонстрации автоматического создания контента с использованием искусственного интеллекта и нейронных сетей.\n",
    "Как это устроено:\n",
    "Oдним нажатием кнопки PodBot.ai генерирует и записывает эпизод подкаста на интересующую вас тему. Завершено созданным хостом, исследованным, но составленным контентом, открывающим музыкальным резюме и фотографией на обложке.\n",
    "PodBot запускает модифицированную (точно настроенную) модель GPT-2 (нейронную сеть, опубликованную Open AI). При вводе «заголовка эпизода» Podbot сначала ищет в Интернете и находит соответствующий контент из 4 существующих статей.\n",
    "Затем он суммирует эти статьи до нескольких ключевых предложений, используя API семантической обработки языка.\n",
    "Эти предложения используются в качестве исходных данных для нейронной сети GPT-2 для вывода полного сценария подкаста.\n",
    "Поддельное имя создается для хоста из случайной базы данных, а изображение несуществующего человека создается с помощью styleGAN - (реализация Tensorflow генеративной состязательной сети, которая использует неконтролируемое обучение для создания реалистично выглядящих фотографий поддельных людей. которые не существуют).\n",
    "В то же время PodBot выполняет поиск в Google через API, чтобы найти соответствующую обложку для эпизода. Затем он использует нейронные сети Google High-fidelity для преобразования текста в речь, чтобы преобразовать текст в реалистично звучащий человеческий голос.\n",
    "В завершение PodBot выбирает бесплатную мелодию из библиотеки MP3 и пытается создать приятное реалистичное звучание, открывающее созданный подкаст."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](26.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocaloid\n",
    "Vocaloid (от англ. vocal — «вокал» и англ. android — «андроид») — программное обеспечение фирмы Yamaha Corporation, имитирующее голос поющего человека на основе заданной мелодии и текста. Использует технологию полного синтеза речи по правилам с использованием предварительно запомненных отрезков естественного языка. Включает в себя редактор для работы с текстом и мелодией, синтезатор поющего голоса и библиотеки исполнителей, также называемых вокалоидами. При создании таких библиотек используется голос певца-человека, голос которого разбивается на небольшие фрагменты, обрабатывается и записывается в базу данных. Существуют тестовые образцы пения, показывающие сходства и различия между исходным человеческим голосом и соответствующим ему синтезированным голосом вокалоида.\n",
    "\n",
    "При работе с программой пользователь вводит мелодию нового произведения, указывает для каждой ноты соответствующую фонему песни в формате X-SAMPA, после чего Vocaloid, используя выбранную библиотеку исполнителя, синтезирует пение. Предусмотрена возможность изменения тембра, скорости, частот, наложения различных эффектов.\n",
    "История развития\n",
    "Принципы обработки сигнала, используемые в программе, были разработаны в Барселонском университете Помпеу Фабра (англ.)русск. в начале 2000-х годов при содействии и финансировании со стороны корпорации Yamaha. Впоследствии, наработки команды студентов университета были использованы в качестве основы для создания коммерческого продукта Yamaha VOCALOID.\n",
    "\n",
    "Проект был анонсирован компанией Yamaha в 1998 году и релиз состоялся в 1999 году, но не имел продуктов певцов и можно было записывать голос реального человека. В 2004 году были выпущены первые продукты проекта — Leon и Lola. Программа была выпущена не под маркой Yamaha Corporation, однако программный пакет Vocaloid Singer Libraries, разработанный по лицензиям другими фирмами, включал в себя программное обеспечение Yamaha Vocaloid. Программы Leon, Lola и Miriam были выпущены фирмой Zero-G Limited, в то время как MEIKO (использует голос японской певицы Мэйко Хайго) и KAITO были выпущены под маркой Crypton Future Media.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](27.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строительство объектов. Autodesk Construction IQ. \n",
    "Construction IQ (ранее известный как Project IQ) – интеллектуальный помощник для проектов строительства в которых применяется платформа Autodesk BIM 360. Использующий методы машинного обучения, Construction IQ собирает и анализирует данные о качестве и безопасности строительных объектов, возможных рисках проекта. Например, выявляет работы с высокой вероятностью сдвига сроков и другие риски. Construction IQ извлекает информацию из зафиксированных данных проекта – результатов наблюдений и аудитов, журналов технадзора, фотографий, технических заданий, отчетов исполнителей и других проектных документов. Все это используется для идентификации, анализа и приоритезации рисков проекта. Результаты анализа рисков, выполненные Construction IQ представляются пользователям в Project Home – едином окне, отображающем ключевую информацию о проекте, включая прогресс по работам, интерактивную модель объекта, данные с камер т.п."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](28.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Генерация контента\n",
    "### Pages by Headlime\n",
    "Данное решение прдставленно компанией Headlime.\n",
    "Основная идея:\n",
    "Создание страницы(сайта) с помощью нейросети GPT-3 за несколько минут. Необходимо лишь сгенерировать дизайн страницы и заголовк.\n",
    "\n",
    "Так же компания headlime предлагает и другие решения на основе GPT-3\n",
    "Например:\n",
    "Мкетинговый копирайте на базе GPT-3\n",
    " ИИ позволит вам быстрее создавать более эффективные маркетинговые материалы. Headlime использует искусственный интеллект, чтобы сделать за вас копирайтинг. От рекламы в Facebook до заголовков - наш ИИ придумывает текст, который конвертирует.\n",
    "Работает на GPT-3 от OpenAI.\n",
    "Реклама в Facebook, заголовки, генератор идей и многое другое \n",
    "А так же: Умный редактор текстов и документов, помощник в введение блога, интелектуальный помощник в написании текстов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](30.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](29.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
