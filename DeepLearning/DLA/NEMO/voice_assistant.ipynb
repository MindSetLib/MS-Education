{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0f2386-d62f-4eea-8a03-2cf093938e7e",
   "metadata": {},
   "source": [
    "# Голосовой помощник\n",
    "## Демонстрационный пайплайн использования акустических моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed8a79d-67e2-47f0-b434-52c3cc5ac646",
   "metadata": {},
   "source": [
    "### Установка переменных среды и импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38380c0-c86f-4762-a439-182c144d9f57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/home/jovyan/work/HF_cache/'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1, 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2478853d-05a6-4361-becf-9efa2534f602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "from sbert_punc_case_ru import SbertPuncCase\n",
    "from peft import PeftModel, PeftConfig\n",
    "from TeraTTS import TTS\n",
    "from ruaccent import RUAccent\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee386d7-a24b-4ddf-9419-e76c2d1b13a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device_0 = torch.device('cuda:0')\n",
    "device_1 = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ecf94d-c483-4522-b63e-6ea38e5ef740",
   "metadata": {},
   "source": [
    "### Загрузка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab0a2f01-0a3d-4f77-a7e9-b49209eafdae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-12-11 08:36:06 mixins:170] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-12-11 08:36:07 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    bucketing_weights: ''\n",
      "    \n",
      "[NeMo W 2023-12-11 08:36:07 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2023-12-11 08:36:07 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-12-11 08:36:07 features:289] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-12-11 08:36:09 nemo_logging:349] /home/jovyan/.cache/pypoetry/virtualenvs/speech-pipe-aX1LTVkJ-py3.10/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-12-11 08:36:09 rnnt_models:211] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2023-12-11 08:36:13 save_restore_connector:249] Model EncDecRNNTBPEModel was successfully restored from /home/jovyan/work/HF_cache/hub/models--nvidia--stt_ru_conformer_transducer_large/snapshots/687d02db291e931455cf321abd625ef2b7f0b1a9/stt_ru_conformer_transducer_large.nemo.\n"
     ]
    }
   ],
   "source": [
    "# Модель для распознавания речи nvidia/stt_ru_conformer_transducer_large\n",
    "asr_model = nemo_asr.models.EncDecRNNTBPEModel.from_pretrained(\"nvidia/stt_ru_conformer_transducer_large\")\n",
    "asr_model = asr_model.to(device_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "620584b9-b4c8-4e28-9fdf-26ecde1f279d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Модель для рескоринга bond005/ruT5-ASR и правки орфографии, а также функция для её использования\n",
    "tokenizer_for_rescoring = T5Tokenizer.from_pretrained('bond005/ruT5-ASR')\n",
    "model_for_rescoring = T5ForConditionalGeneration.from_pretrained('bond005/ruT5-ASR')\n",
    "model_for_rescoring = model_for_rescoring.to(device_0)\n",
    "    \n",
    "def rescore(text: str, tokenizer: T5Tokenizer,\n",
    "            model: T5ForConditionalGeneration) -> str:\n",
    "    if len(text) == 0:  # if an input text is empty, then we return an empty text too\n",
    "        return ''\n",
    "    ru_letters = set('аоуыэяеёюибвгдйжзклмнпрстфхцчшщьъ')\n",
    "    punct = set('.,:/\\\\?!()[]{};\"\\'-')\n",
    "    x = tokenizer(text, return_tensors='pt', padding=True).to(model.device)\n",
    "    max_size = int(x.input_ids.shape[1] * 1.5 + 10)\n",
    "    min_size = 3\n",
    "    if x.input_ids.shape[1] <= min_size:\n",
    "        return text  # we don't rescore a very short text\n",
    "    out = model.generate(**x, do_sample=False, num_beams=5,\n",
    "                         max_length=max_size, min_length=min_size)\n",
    "    res = tokenizer.decode(out[0], skip_special_tokens=True).lower().strip()\n",
    "    res = ' '.join(res.split())\n",
    "    postprocessed = ''\n",
    "    for cur in res:\n",
    "        if cur.isspace() or (cur in punct):\n",
    "            postprocessed += ' '\n",
    "        elif cur in ru_letters:\n",
    "            postprocessed += cur\n",
    "    return (' '.join(postprocessed.strip().split())).replace('ё', 'е')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d91617d7-b2c7-470f-800d-f64c8317197e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Модель для правки пунктуации от Сбера (опционально)\n",
    "punct_model = SbertPuncCase()\n",
    "punct_model = punct_model.to(device_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64771c5a-7f31-438f-94a0-773fba3b418a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2f0c8a7b41413a84a9c046d3cdc106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# LLM Saiga-Mistral и полезные функции для работы с этой моделью\n",
    "MODEL_NAME = \"IlyaGusev/saiga_mistral_7b_lora\"\n",
    "DEFAULT_MESSAGE_TEMPLATE = \"<s>{role}\\n{content}</s>\"\n",
    "DEFAULT_RESPONSE_TEMPLATE = \"<s>bot\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"Ты — Сайга, русскоязычный автоматический медицинский ассистент. Ты выслушиваешь жалобы людей на проблемы со здоровьем и сообщаешь им предположительный диагноз\"\n",
    "\n",
    "class Conversation:\n",
    "    def __init__(\n",
    "        self,\n",
    "        message_template=DEFAULT_MESSAGE_TEMPLATE,\n",
    "        system_prompt=DEFAULT_SYSTEM_PROMPT,\n",
    "        response_template=DEFAULT_RESPONSE_TEMPLATE\n",
    "    ):\n",
    "        self.message_template = message_template\n",
    "        self.response_template = response_template\n",
    "        self.messages = [{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        }]\n",
    "\n",
    "    def add_user_message(self, message):\n",
    "        self.messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message\n",
    "        })\n",
    "\n",
    "    def add_bot_message(self, message):\n",
    "        self.messages.append({\n",
    "            \"role\": \"bot\",\n",
    "            \"content\": message\n",
    "        })\n",
    "\n",
    "    def get_prompt(self, tokenizer):\n",
    "        final_text = \"\"\n",
    "        for message in self.messages:\n",
    "            message_text = self.message_template.format(**message)\n",
    "            final_text += message_text\n",
    "        final_text += DEFAULT_RESPONSE_TEMPLATE\n",
    "        return final_text.strip()\n",
    "\n",
    "\n",
    "def generate(model, tokenizer, prompt, generation_config):\n",
    "    data = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    data = {k: v.to(model.device) for k, v in data.items()}\n",
    "    output_ids = model.generate(\n",
    "        **data,\n",
    "        generation_config=generation_config\n",
    "    )[0]\n",
    "    output_ids = output_ids[len(data[\"input_ids\"][0]):]\n",
    "    output = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    return output.strip()\n",
    "\n",
    "config = PeftConfig.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_1 #\"auto\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa6bf7ad-496f-47a1-b744-23681ada7abf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def step(inp, meta=''):\n",
    "    if meta == '':\n",
    "        system_prompt = DEFAULT_SYSTEM_PROMPT\n",
    "    else:\n",
    "        system_prompt =  meta\n",
    "    сonversation = Conversation(system_prompt=system_prompt)   \n",
    "    сonversation.add_user_message(inp)\n",
    "    prompt = сonversation.get_prompt(tokenizer)\n",
    "    output = generate(model, tokenizer, prompt, generation_config)\n",
    "    print(inp)\n",
    "    print(output)\n",
    "    print(\"==============================\")\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c17c379-c813-410d-9f13-8c60ffa6f542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TeraTTS - русская модель синтеза речи\n",
    "tts = TTS(\"TeraTTS/natasha-g2p-vits\", add_time_to_end=1.0, tokenizer_load_dict=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e881ad12-5d10-45f6-8f3a-2b4e5f2fea98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Модель расстановки ударений\n",
    "accentizer = RUAccent(workdir=\"./model\")\n",
    "accentizer.load(omograph_model_size='big_poetry', use_dictionary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "912f42f7-c491-4ff2-90cf-7cb191a5fd73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-12-11 08:37:37 cloud:58] Found existing object /home/jovyan/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n",
      "[NeMo I 2023-12-11 08:37:37 cloud:64] Re-using file from: /home/jovyan/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n",
      "[NeMo I 2023-12-11 08:37:37 common:913] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-12-11 08:37:38 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-12-11 08:37:38 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-12-11 08:37:38 features:289] PADDING: 16\n",
      "[NeMo I 2023-12-11 08:37:39 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/jovyan/.cache/torch/NeMo/NeMo_1.21.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n"
     ]
    }
   ],
   "source": [
    "# TitaNet для эмбеддингов\n",
    "titanet_model = nemo_asr.models.EncDecSpeakerLabelModel.from_pretrained(model_name='titanet_large')\n",
    "titanet_model = titanet_model.to(device_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35202298-823b-4f78-a353-56e9092ce9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kNN для пола\n",
    "sex_model = pickle.load(open('./weights/knn_sex_tn.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9517c87-bac7-427b-9558-28b7d3060a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# модель для возраста\n",
    "import torch.nn as nn\n",
    "class FCN2(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(FCN2, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(192, 128)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(torch.relu(self.fc1(x)))\n",
    "        x = self.dropout2(torch.sigmoid(self.fc2(x)))\n",
    "        logits = self.fc(x)  \n",
    "        return logits    \n",
    "\n",
    "age_model = FCN2()\n",
    "age_model.load_state_dict(torch.load('./weights/voice_to_age_tn_FCN2.pth'))\n",
    "age_model = age_model.to(device_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab06bd-a01a-4e3c-bd60-d219fc5ddbd7",
   "metadata": {},
   "source": [
    "### Обработка голосового запроса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a93ac2-580f-4733-aa5a-85f4f9b54faa",
   "metadata": {},
   "source": [
    "Загрузка записи голосового запроса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26bf09b2-a0ed-42a3-86e0-bda2c6fa89c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Нужно указать путь к wav. файлу с тестовым голосовым запросом\n",
    "wav_file = './data/test_asr.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77fb0b5-14c5-493b-9ae5-9280a6e3a7eb",
   "metadata": {},
   "source": [
    "Получение эмбеддинга с помощью TitaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75b6b7d9-f75f-453d-b3b7-9c4104bc8bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.72 s, sys: 691 ms, total: 2.41 s\n",
      "Wall time: 2.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tn_emb = titanet_model.get_embedding(wav_file).squeeze().detach().cpu().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196774dd-9178-48b6-bf7e-c570aead19e7",
   "metadata": {},
   "source": [
    "Определение пола"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12e18c1e-8e1a-4f2e-847d-01afa911f9bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 980 ms, sys: 57.3 ms, total: 1.04 s\n",
      "Wall time: 187 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sex = sex_model.predict([tn_emb])[0]\n",
    "sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8400017-7acd-42f7-82d8-866644a3e020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Мэппинг для запроса\n",
    "if sex == 0:\n",
    "    meta1 = 'женского пола'\n",
    "else:\n",
    "    meta1 = 'мужского пола'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f0166-3654-4772-adb9-f9049035c4b6",
   "metadata": {},
   "source": [
    "Определение возрастного интервала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da12d2ed-c99c-4586-8442-d1999e18031a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.57 ms, sys: 2.27 ms, total: 3.85 ms\n",
      "Wall time: 2.57 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "age_model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = torch.FloatTensor([tn_emb]).to(device_0)\n",
    "    outputs = age_model(inputs)\n",
    "    _, predicted = outputs.max(1)\n",
    "    age = predicted[0].item()\n",
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d269b472-1e1c-4ea3-a523-9f99810ac04c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Мэппинг для запроса\n",
    "if age == 0:\n",
    "    meta2 = 'возрастом моложе 25 лет'\n",
    "elif age == 1:\n",
    "    meta2 = 'возрастом в пределах от 25 до 40 лет'\n",
    "else:\n",
    "    meta2 = 'возрастом старше 40 лет'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8c99881-78f8-4252-bc71-4d1df5cf4b06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta = f\"Ты — Сайга, русскоязычный автоматический медицинский ассистент. Ты выслушиваешь жалобу пациента {meta1} {meta2} на проблемы со здоровьем и сообщаешь ему предположительный диагноз\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01672791-28d8-4df3-b27f-68fbf012ad5d",
   "metadata": {},
   "source": [
    "Расшифровка голоса в текст с помощью ru_conformer_transducer_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0911bc19-abe5-4e07-ba5c-97e34e5f53fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dafd443f4841de804507b4827c0602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 62 ms, total: 1.28 s\n",
      "Wall time: 560 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'у меня поднялась температура заложила нос еще болит поясница'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "text0 = asr_model.transcribe([wav_file])[0][0]\n",
    "text0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1c740b-2034-4f22-a2bf-3fbc20560615",
   "metadata": {
    "tags": []
   },
   "source": [
    "Исправление орфографии с помощью ruT5-ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56fa608f-8892-44aa-bb0c-3e5a65077749",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 726 ms, sys: 11.8 ms, total: 738 ms\n",
      "Wall time: 734 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'у меня поднялась температура заложило нос еще болит поясница'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "text1 = rescore(text0, tokenizer_for_rescoring, model_for_rescoring)\n",
    "text1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54758c7a-86c3-49eb-a947-e8b4f5c97cce",
   "metadata": {},
   "source": [
    "Исправление пунктуации и заглавных букв с помощью SbertPuncCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8629715a-ee9e-487e-a528-af0b8ce6fb9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 331 ms, sys: 39 ms, total: 370 ms\n",
      "Wall time: 368 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'У меня поднялась температура, заложило нос, еще болит поясница.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "text2 = punct_model.punctuate(text1)\n",
    "text2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a47ce48-67ff-412b-bece-dafa9f47533d",
   "metadata": {},
   "source": [
    "Передача вопроса в языковую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f70c703-e109-43e9-a4bb-38992e3a4ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У меня поднялась температура, заложило нос, еще болит поясница.\n",
      "Ваша симптоматика может указывать на инфекционное заболевание, возможно, это грипп или общий респираторный вирус. Важно немедленно обратиться к врачу для получения лечения и консультации. Также важно придерживаться правил гигиены и избегать контакта с другими людьми, чтобы не передавать инфекцию.\n",
      "==============================\n",
      "CPU times: user 56.5 s, sys: 153 ms, total: 56.6 s\n",
      "Wall time: 56.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text3 = step(text2, meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b94a43-886c-4e67-b5df-0dbcc4159962",
   "metadata": {},
   "source": [
    "Расстановка ударений в ответе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ccde8ec-3a51-4e2d-916a-9964c2e41cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.66 s, sys: 228 ms, total: 2.89 s\n",
      "Wall time: 113 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'в+аша симптом+атика м+ожет ук+азывать н+а инфекци+онное заболев+ание, возм+ожно, +это гр+ипп +или +общий респират+орный в+ирус. в+ажно нем+едленно обрат+иться к врач+у дл+я получ+ения леч+ения и консульт+ации. т+акже в+ажно прид+ерживаться пр+авил гиги+ены и избег+ать конт+акта с друг+ими людьм+и, чт+обы н+е передав+ать инф+екцию.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "text4 = accentizer.process_all(text3)\n",
    "text4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219295fd-4de9-4839-824c-0e2f926f08fd",
   "metadata": {},
   "source": [
    "Синтез голосового ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82c7423a-d08d-448e-9bcf-aa2cc138faa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 26s, sys: 2.61 s, total: 3min 29s\n",
      "Wall time: 7.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 'length_scale' можно использовать для замедления аудио для лучшего звучания (по умолчанию 1.1, указано здесь для примера)\n",
    "audio = tts(text4, lenght_scale=2.0)  # Создать аудио. Можно добавить ударения, используя '+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9974315e-d221-4a86-a94e-f59aa0c74a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Нужно указать путь, куда сохранять wav. файл с голосовым ответом\n",
    "#tts.play_audio(audio)  # Воспроизвести созданное аудио\n",
    "tts.save_wav(audio, \"./reports/test_tts.wav\")  # Сохранить аудио в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951dbb6f-ac2d-4c2d-aa89-8e5ca052ae0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e904ef9-1f35-4b26-b4ea-1bc0728d2f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_pipe",
   "language": "python",
   "name": "speech_pipe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
