{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation using GPT2. Opentalks.ai workshop notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mset.space - ml platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.2.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from transformers) (20.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.55.2)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.9.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_shortcut = 'gpt2'\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(weights_shortcut)\n",
    "model = GPT2LMHeadModel.from_pretrained(weights_shortcut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = 'What is machine learning'\n",
    "encoded_prompt = tokenizer.encode(prompt_text, return_tensors=\"pt\")\n",
    "bad_words_ids = [tokenizer.encode(bad_word, add_prefix_space=True) for bad_word in ['idiot', 'stupid', 'shut up']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2061,  318, 4572, 4673]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "encoded_prompt = encoded_prompt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is machine learning?\n",
      "\n",
      "Machine learning is a new field of research that has been around for decades. It's not just about the data, it's about how we learn. Machine learning is about understanding what you're doing and how you can improve it.\n",
      "\n",
      "The problem with machine learning is that it's very hard to understand what you're doing. You have to be able to see what you're doing. And then you need to know what you're doing. So if you're going to do something like this, you need to know what you're doing.\n",
      "\n",
      "So I think there's a lot of work that needs to be done to get people to understand what machine learning is. But I think it's important to understand what machine learning is.\n",
      "\n",
      "How does machine learning compare to other fields of research?\n",
      "\n",
      "Machine learning is a new field of research that has been around for decades. It's not just about the data, it's about how we learn. Machine learning is about understanding what you're doing and how you can improve it.\n",
      "\n",
      "I think there's a lot of work that needs to be done to get people to understand what machine learning is. But I think it's important to understand what machine learning is.\n",
      "\n",
      "Do you think machine learning will ever become mainstream?\n",
      "\n",
      "Machine learning is a new field of research that has been around for decades. It's not just about the data, it's about how we learn. Machine learning is about understanding what you're doing and how you can improve it.\n",
      "\n",
      "It's not just about the data, it's about how we learn.\n",
      "\n",
      "You've said that you don't want to make any predictions about what your future will look like. What are your plans for the future?\n",
      "\n",
      "I'm not going to say anything about what I'm going to do. I'm not going to say anything about what I'm going to do. I'm not going to say anything about what I'm going to do.\n",
      "\n",
      "But I am going to tell you what I'm going to do. I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you what I'm going to do.\n",
      "\n",
      "I'm going to tell you\n"
     ]
    }
   ],
   "source": [
    "encoded_result = model.generate(encoded_prompt, \n",
    "                                eos_token_id=tokenizer.eos_token_id, max_length= 1000,\n",
    "                                temperature=5, top_p=0.1, repetition_penalty=1.01,bad_words_ids=bad_words_ids\n",
    "                               )\n",
    "result = tokenizer.decode(encoded_result[0], skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2061,   318,  4572,  4673,    30,   198,   198, 37573,  4673,   318,\n",
       "          257,   649,  2214,   286,  2267,   326,   468,   587,  1088,   329,\n",
       "         4647,    13,   632,   338,   407,   655,   546,   262,  1366,    11,\n",
       "          340,   338,   546,   703,   356,  2193,    13, 10850,  4673,   318,\n",
       "          546,  4547,   644,   345,   821,  1804,   290,   703,   345,   460,\n",
       "         2987,   340,    13,   198,   198,   464,  1917,   351,  4572,  4673,\n",
       "          318,   326,   340,   338,   845,  1327,   284,  1833,   644,   345,\n",
       "          821,  1804,    13,   921,   423,   284,   307,  1498,   284,   766,\n",
       "          644,   345,   821,  1804,    13,   843,   788,   345,   761,   284,\n",
       "          760,   644,   345,   821,  1804,    13,  1406,   611,   345,   821,\n",
       "         1016,   284,   466,  1223,   588,   428,    11,   345,   761,   284,\n",
       "          760,   644,   345,   821,  1804,    13,   198,   198,  2396,   314,\n",
       "          892,   612,   338,   257,  1256,   286,   670,   326,  2476,   284,\n",
       "          307,  1760,   284,   651,   661,   284,  1833,   644,  4572,  4673,\n",
       "          318,    13,   887,   314,   892,   340,   338,  1593,   284,  1833,\n",
       "          644,  4572,  4673,   318,    13,   198,   198,  2437,   857,  4572,\n",
       "         4673,  8996,   284,   584,  7032,   286,  2267,    30,   198,   198,\n",
       "        37573,  4673,   318,   257,   649,  2214,   286,  2267,   326,   468,\n",
       "          587,  1088,   329,  4647,    13,   632,   338,   407,   655,   546,\n",
       "          262,  1366,    11,   340,   338,   546,   703,   356,  2193,    13,\n",
       "        10850,  4673,   318,   546,  4547,   644,   345,   821,  1804,   290,\n",
       "          703,   345,   460,  2987,   340,    13,   198,   198,    40,   892,\n",
       "          612,   338,   257,  1256,   286,   670,   326,  2476,   284,   307,\n",
       "         1760,   284,   651,   661,   284,  1833,   644,  4572,  4673,   318,\n",
       "           13,   887,   314,   892,   340,   338,  1593,   284,  1833,   644,\n",
       "         4572,  4673,   318,    13,   198,   198,  5211,   345,   892,  4572,\n",
       "         4673,   481,  1683,  1716,  8661,    30,   198,   198, 37573,  4673,\n",
       "          318,   257,   649,  2214,   286,  2267,   326,   468,   587,  1088,\n",
       "          329,  4647,    13,   632,   338,   407,   655,   546,   262,  1366,\n",
       "           11,   340,   338,   546,   703,   356,  2193,    13, 10850,  4673,\n",
       "          318,   546,  4547,   644,   345,   821,  1804,   290,   703,   345,\n",
       "          460,  2987,   340,    13,   198,   198,  1026,   338,   407,   655,\n",
       "          546,   262,  1366,    11,   340,   338,   546,   703,   356,  2193,\n",
       "           13,   198,   198,  1639,  1053,   531,   326,   345,   836,   470,\n",
       "          765,   284,   787,   597, 16277,   546,   644,   534,  2003,   481,\n",
       "          804,   588,    13,  1867,   389,   534,  3352,   329,   262,  2003,\n",
       "           30,   198,   198,    40,  1101,   407,  1016,   284,   910,  1997,\n",
       "          546,   644,   314,  1101,  1016,   284,   466,    13,   314,  1101,\n",
       "          407,  1016,   284,   910,  1997,   546,   644,   314,  1101,  1016,\n",
       "          284,   466,    13,   314,  1101,   407,  1016,   284,   910,  1997,\n",
       "          546,   644,   314,  1101,  1016,   284,   466,    13,   198,   198,\n",
       "         1537,   314,   716,  1016,   284,  1560,   345,   644,   314,  1101,\n",
       "         1016,   284,   466,    13,   314,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345,\n",
       "          644,   314,  1101,  1016,   284,   466,    13,   198,   198,    40,\n",
       "         1101,  1016,   284,  1560,   345,   644,   314,  1101,  1016,   284,\n",
       "          466,    13,   198,   198,    40,  1101,  1016,   284,  1560,   345],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is preprocessed from here: https://github.com/square/MimicAndRephrase/tree/master/datasets/Sentiment/Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_dataset_tensor(dataset_path):\n",
    "    with open(dataset_path) as f:\n",
    "        tokenized_dataset = [tokenizer.encode(line) for line in f]\n",
    "\n",
    "    samples_num = len(tokenized_dataset)\n",
    "    max_tokens_num = max(map(len, tokenized_dataset))\n",
    "\n",
    "    input_ids = np.full((samples_num, max_tokens_num), tokenizer.pad_token_id, dtype=np.int64)\n",
    "    for i, tokens in enumerate(tokenized_dataset):\n",
    "        input_ids[i, :len(tokens)] = tokens\n",
    "\n",
    "    return torch.from_numpy(input_ids)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "train_data_tensor = get_dataset_tensor(dataset_path='paraphrase_dataset.txt')\n",
    "train_dataloader = DataLoader(train_data_tensor, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def train_model(model, training_data, epochs_num):\n",
    "    optimizer = AdamW(model.parameters(), lr=3e-5, weight_decay=1)\n",
    "\n",
    "    train_loss = []\n",
    "\n",
    "    for _ in tqdm(range(epochs_num), total=epochs_num):\n",
    "        for input_ids in training_data:\n",
    "            model.train()\n",
    "\n",
    "            input_ids = input_ids.to(device)\n",
    "            loss = model(input_ids, labels=input_ids)[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "                \n",
    "    return model, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17439,  2626,   465,  8251,  4613,   220,  4907,    93,   198,   198,\n",
       "          464,  1306,   640,   314,   373,   287,   262,  2119,    11,   314,\n",
       "         2497,   257,   582,   351,   257,  1263,  2042,  6877,    13,   679,\n",
       "          373,  5762,   257,  2330,  6877,   290,   257,  2042,  9839,    13,\n",
       "          679,   531,    11,   366,    40,  1101,  1016,   284,  1011,   345],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frank lost his keys -> ix's is the one for me :D. Also, and for\n"
     ]
    }
   ],
   "source": [
    "encoded_prompt = tokenizer.encode('Frank lost his keys -> ', return_tensors=\"pt\").to(device)\n",
    "encoded_result = model.generate(encoded_prompt, \n",
    "                                eos_token_id=tokenizer.eos_token_id, do_sample=True)\n",
    "result = tokenizer.decode(encoded_result[0], skip_special_tokens=True)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  464,  9294,   286,  8237,   373,   269,   967,   276,  4613,   314,\n",
       "          716,  6507,   546,   262,  8237,     0,   198, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-608cb9de89ed>:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for _ in tqdm(range(epochs_num), total=epochs_num):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bbd124761fa4ed4965c7c4d743c4ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetuned_model, metrics_history = train_model(model, train_dataloader, epochs_num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "encoded_prompt = tokenizer.encode('I have a car acident today -> ', return_tensors=\"pt\").to(device)\n",
    "encoded_result = finetuned_model.generate(encoded_prompt, \n",
    "                                          eos_token_id=tokenizer.eos_token_id,\n",
    "                                          num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a car acident today -> ive had a car accident and it's totaled\u0001 and\n"
     ]
    }
   ],
   "source": [
    "result = tokenizer.decode(encoded_result[0], skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   40,   423,   257,  1097,   936,   738,  1909,  4613,   220,   425,\n",
       "          550,   257,  1097,  5778,   290,   340,   338, 39398,   189,   290],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      " have\n",
      " a\n",
      " car\n",
      " ac\n",
      "ident\n",
      " today\n",
      " ->\n",
      " \n",
      "ive\n",
      " had\n",
      " a\n",
      " car\n",
      " accident\n",
      " and\n",
      " it\n",
      "'s\n",
      " totaled\n",
      "\u0001\n",
      " and\n"
     ]
    }
   ],
   "source": [
    "for cur_sample_tokens in encoded_result[0]:\n",
    "    # print(int(cur_sample_tokens))\n",
    "    print(tokenizer.decode(int(cur_sample_tokens), skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "* Compute validation metrics: perplexity/BLEU/ROUGE\n",
    "* Logging into tensorboard\n",
    "* Generate N candidates and filter or rerank\n",
    "* Analyze errors and improve dataset\n",
    "* Improve training: masking, `lr_scheduler`, multi-gpu training\n",
    "* Improve generation: try different strategies\n",
    "* Improve the model: use bigger model, try different architecrures (DialoGPT2, XLNet, CTRL  etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
